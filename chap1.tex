
\documentclass{book}

\usepackage{graphicx}

\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{multirow}
\usepackage{amsmath}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{leftidx}% http://ctan.org/pkg/leftidx


\title{Numerical Methods for Robotics}

\author{ 
  Nicolas Mansard\\
        LAAS\\
        31077 Toulouse Cedex 4, France\\
 { \footnotesize Email: {\tt Nicolas.Mansard@laas.fr} }
}

\date{}

\input{commands.tex}

\begin{document}
\maketitle

\tableofcontents

% ------------------------------------------------------------------------------
\chapter{Outline of the class}

The objective of the class is to provide numerical methods to express, compute and reason about a motion to be executed by a physical platform. In particular, we will deal with representation of the motion, numerical resolution of algebraic equations and automatic numerical methods to approximate the solution to equality problems or minimization problems.

We will start with the static problem of finding one configuration answering to a set of constraints, typically finding a configuration such that the end effector of the robot is at a given position and orientation (chap 1: inverse geometry). This problem does not comprehend any concept of trajectory: only the final configuration is considered. In Chap. 2, we will consider the problem of finding the configuration velocity that brings the system closer to a given goal. This problem, named inverse kinematics, leads by integration to the resolution of the inverse geometry problem, and will be shown to be of a much simpler class of difficulty. Coming from geometry then kinematics, we will consider the system dynamics in the third chapter. In particular, we will present the inverse dynamics problem as an increment of the inverse kinematics problem. Finally, the last chapter we really consider the robot trajectory from an initial position to the final goal as a single object, and exhibit the methods to approximate the system optimality on the full trajectory. Compared to the initial static optimization problem, this last \emph{optimal control} problem is of a more complex class, but can be approximate to a static problem to the cost of a increase of dimensionality.

Each part of the class will be an oportunity to visit a general class of numerical resolution methods. In Chapter 1, we will introduce the Newton iterative optimization method. In Chapter 2, the pseudo-inverse will be the key tool. Chapter 3 we be the occasion to consider the optimization under constraints. Finally, in Chapter 4, we will quickly recall the optimal-control framework and consider more in detail the linear-quadratic regulator (LQR). 

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\part{Inverse geometry}

We mainly consider in the part open kinematic chain, that is to say a tree of rigid bodies attached two by two by joints. Recall that the configuration space of the robot is a representation (desirably minimal) that uniquely defined the position of all the bodies of the robot. Before discussing the robot geometry, it is important to introduce the concept to manipulate a body in space. The correct structure to do so is the special Euclidean group $SE(3)$, which is described in \refsec{se3}.

The direct geometry function\footnote{The map that gives the position of the end effector with respect to the robot configuration is often called direct kinematics. The kinematics being the branch of mechanics that studies the \textit{motion} ($\kappa \iota \nu \eta \mu \alpha$, motion in Greek) of sets of points, \mie velocity, acceleration, we rather use direct geometry for the function $h$.} of the robot is the function that map one configuration of the robot to the corresponding placement (position and orientation) of the robot in the space. For open-chain robots, this function is very easy to compute. Performing an action with the robot often comes to finding one configuration where the end-effector is at the right place with the right orientation. Finding such a configuration is called the inverse geometry problem\footnote{This problem is often called \emph{inverse kinematics} in the litterature.}. 

In the general case, the inverse geometry problem is written as an algebraic problem, and solving it reduces to finding the roots (possibly several or a manifold of them) of a polynomials of several variables (one per degrees of freedom). In some particular cases, algebraic solutions exists to automatically or semi-automatically compute exact solutions or nearly exact solution to this problems. The most studied particular case has been the non-redundant manipulator with six degrees of freedom: in that case, we have the same number of constraints and variables. These methods are described in \refsec{anainvgeom}. 

Alternatively, numerical methods can be used to solve the problem in the general case, using descent methods. A basic introduction to the numerical methods is given in \refsec{numeric}, and their application to the inverse geometry problem is given in \refsec{numinvgeom}.

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\chapter{Special Euclidean Group} \label{sec:se3}

\section{Euclidean space $\mathbb{E}^3$}

We consider the three-dimensional Euclidean space  $\mathbb{E}^3$. The Euclidean structure is totaly defined by selecting a representation $\mathbb{E}^3$, by selecting a coordinate frame, \mie an origin $\mathcal{O}$ and three independant direction $e_1,e_2,e_3$. In that case, any point $p \in \mathbb{E}^3$ can be identified with a vector $\mbf{p} \in \mathbb{R}^3$ which represents it:
\[ p \repr \mbf{p} = \BIN x \\ y \\ z \BOUT \in \mathbb{R}^3 \] 
where the symbol $\repr$ denotes the representation. In $\mathbb{E}^3$, a vector $v$ is determined by a pair of point $a$ and $b$. Its coordinates are defined in $\mathbb{R}^3$ by 
\[ v \repr \mbf{v} = \mbf{b} - \mbf{a} \]
where $\mbf{a},\mbf{b}$ are the representation of $a$ and $b$ in the chosen coordinate system.

The canonical basis on $\mathbb{R}^3$ implicitely defines a dot product $<v|w> \triangleq \mbf{v}^T \mbf{w}$ and a norm $|| v || = || \mbf{v}||_2 = \sqrt{<v|v>} = v_1^2 + v_2^2 + v_3^2$ with $v_1,v_2,v_3$ the components of $\mbf{v}$ ($\mbf{v} = (v_1,v_2,v_3)$).

Coming from the coordinate system, the cross product operator between two vectors $v,w$ is also defined by:
\[ v \times w  = \BIN v_2 w_3 - v_3 w_2 \\ v_3 w_1 - v_1 w_3 \\ v_1 w_2 - v_2 w_1 \BOUT \]
The cross product is an internal composition law of $\mathbb{R}^3$.

The transformations of $\mathbb{E}^3$ that preserves the dot and cross product are called the special Euclidean transformations (or rigid-body motion). The ``special'' attribute corresponds to the preservation of the cross product, \mie the orientation. The preservation of the dot product directly induces the preservation of the distances (both are equivalent using that $<u|v> = \frac{1}{4} ( ||u+v||^2 - ||u-v||^2)$). The set is denoted $SE(3)$:
\[ SE(3) \triangleq \Big\{ g : \mathbb{E}^3 \rightarrow \mathbb{E}^3, \textrm{ so that } \forall x,y \in \mathbb{E}^3, || g(x) - g(y) || = ||x - y|| \Big\} \]

The set $SE(3)$ equiped with the composition of application is a group (\mie the composition keeps the elements in the set, the 0 motion is the neural elements and any transformation is revertible). 

In the remaining, we will define some possible representations of $SE(3)$, \mie some vector spaces that surjectively maps $SE(3)$.


\section{Rotation $SO(3)$}

\subsection{Matrix representation}
We start with the subset of $SE(3)$ that keeps the origin fixed. This set is denoted $SO(3)$ for special orthogonal group. 
\[ SO(3) \triangleq \Big\{ g : \mathbb{E}^3 \rightarrow \mathbb{E}^3, \textrm{ so that } \forall x,y \in \mathbb{E}^3, || g(x) - g(y) || = ||x - y|| \textrm{ and } g(0) = 0 \Big\} \]
It can be shown that any elements $r$ of $SO(3)$ is a linear application in $\mbf{R}^3$: $SO(3)$ is a subgroup of the group of linear applications on $\mathbb{R}^3$ denoted by $GL(3)$. Any element of $SO(3)$ can then be represented by its action on the canonical basis, \mie its matrix in $\mathbf{R}^{3\times 3}$.

From the definition of $SE(3)$, we can easily show that the transformation of the canonical basis is still orthonormal, \mie that
\[ \forall i = 1..3, || r(e_i) || = 1 \]
\[ \forall i,j=1..3, i \neq j,  <r(e_i)|r(e_j)> = 0 \]
This defines six constraints, that can be summarized by 
\EIN{rtr} R R^T = I \EOUT
where $R = [ r(e_1) r(e_2) r(e_3) ]$ is the matrix representation of $r$. In addition, since the orientation (cross product) is preserved, we also have the positivity of the determinant, \mie:
\[ det(R) = +1\]

\subsection{Angular velocities $\mathfrak{so}(3)$}

Consider now a curve $r(t)$ in $SO(3)$ represented by $R(t)$ in $\mathbb{R}^{3\times3}$. By derivation of \eq{eq:rtr}, we have that:
\[ \dot{R}(t) R(t)^T = - ( \dot{R}(t) R(t)^T )^T \]
Say otherwise, $\dot{R}(t) R(t)^T$ is antisymmetric. The group of antisymmetric matrices is denoted $\mathfrak{so}(3)$:
\[ \mathfrak{so}(3) \triangleq \Big\{ \BIN 0 & -w_3  & w_2 \\ w_3 & 0 & -w_1 \\ -w_2 & w_1 & 0 \BOUT, (w_1,w_2,w_3) \in \mathbb{R}^3 \Big\} \]
The group $\mathfrak{so}(3)$ is evidently isomorph to $\mathbb{R}^3$. We denote $w \in \mathbb{R}^3 \rightarrow \hat{w} \in \mathfrak{so}(3)$ the isomorphism from $\mathbb{R}^3$ to $\mathfrak{so}(3)$ and $\check{.}$ its reciprocal. The vector $w(t)$ can be identified to the angular velocity corresponding to $r(t)$.

Consider now the curve obtained by integration of a constant velocity $w \in \mathfrak{so}(3)$:
\[ \forall t>0, \dot{R}(t) = \hat{w} R(t), R(0) \in SO(3) \]
The differential equation is uniquely integrable in $\mathbb{R}^3$ (theorem of Cauchy). The expression of the integrale is obtained using the exponential of $\hat{w}$ defined by its power serie:
\[ exp( t \hat w  ) = e^{t \hat w} = \sum_{n=0}^{+\infty} \frac{1}{n!} (t \hat w)^n \]
Using this definition, the integrale is:
\[ R(t) = R(0) e^{t \hat w} \]
It is easy to prove that the exponential satisfies the differential equation, and its uniqueness is ensured by the theorem of Cauchy.

From the differential construction, we obtain that $e^{t \hat w}$ is a rotation matrix. This property can also be proved directly, by verifying that ${e^{t \hat w}}^T e^{t \hat w} = I$ using the power serie, and by showing that $det(e^{t \hat w})=1$ by continuity from $det(e^0)=1$.

\subsection{Rodrigues's formula}

The infinite power serie of the exponential map easily reduces to a simple formula using the simple structure of $\mathfrak{so}(3)$. Indeed, we have the two following properties:
\[ \hat{w}^2 = ww^T - I_3 \textrm{ and } \hat{w}^3 = -\hat{w} \]
The development immediatly reduces to:
\[ e^{t \hat w} = I + sin(t) \hat{w} + \frac{1-cos(t)}{t} \hat{w}^2 \]
using the serie of $\sin(t) = \sum \frac{(-1)^{n}}{(2n+1)!} t^{2n+1} $ and $\cos(t) = \sum \frac{(-1)^2}{(2n)!} t^{2n}$.
This expression is named the Rodrigues's formula.

The exponential map is an application from $\mathfrak{so}(3)$ to $SO(3)$:
\[ exp: w \in \mathfrak{so}(3) \rightarrow e^{\hat{w}} \]
The cases studied above is only decoupled expression, $w$ being the direction and $t$ the magnitude of the rotation. From the Rodrigues's formulat, we directly see that the exponential is not injective, since the norm can be chosen modulo $2\pi$.


\subsection{Canonical exponential coordinates}

The exponential map from $\mathfrak{so}(3)$ generates rotation matrices. It can be shown that the map generates all the group $SO(3)$, that is to say that it is surjective (onto). This is done by building the reciprocal, called the logarithm map. Being given a rotation matrix $R$ with $r_{ij}$ its components, the logarithm is defined by:
\[ log : R\in SO(3) \rightarrow w \in \mathfrak{so}(3) \]
\[ || w || = cos^{-1} ( \frac{\textrm{trace}(R) -1}{2}) , \quad \frac{1}{||w||} w = \frac{1}{2\sin(||w||)} \BIN r_{32}-r_{23} \\  r_{13}-r_{31} \\  r_{21}-r_{12} \BOUT \]

The surjectivity guarantees that any rotation matrix $R$ can be generated by taking the exponential of a vector of $\mathbb{R}^3$. The group $SO(3)$ can therefore be represented using $\mathbb{R}^3$. This is called a parametrization of the group. We call this parametrization the canonical exponential coordinates.

Compared to the representation using rotation matrix, of dimension $9$ but with six constraints on the effect on the canonical basis, this representation is of dimension 3 without any constraint. It is therefore minimal. 

Intuitively, the coordinates $w = \theta u$ with $\theta = || w ||$ and $u = \frac{1}{\theta} w$ corresponds to the integration of an unitary rotation velocity during a time $\theta$, or said differently to a rotation of an angle $\theta$ around the direction $u$. It corresponds to the older results that any rotation of a solid in space can be brought back to a pure rotation around a particular axis. The coordinates are also named ``angle vector'' or ``u theta'' for this reason.


\section{General overview: standard Lie Group representation}

The definition of the canonical coordinates seems pretty artificial, since we had to introduce a complex map coming from an arbitrary differential equation. In fact, the process to obtain the parametrization is coming from the very topological structure of the group. The same process can be used for obtaining usefull parametrization on similar topologies. We make here a brief overview of the topological tools that where used, in the general case.

\subsection{Differential manifold}
A differential manifold $\mathcal{M}$ is a set that is locally diffeomorphic to a vector space $\mathbb{R}^n$, that is to say, in any point $x \in \mathcal{M}$, there exists a local neighborhood $\mathcal{U}$ of $x$ with a diffeorphism $\psi$ from $\mathcal{U}$ to a neighborhood of $0_n$ in $\mathbb{R}^n$. A collection of $\mathcal{U},\phi$ covering $\mathcal{M}$ is called an atlas of $\mathcal{M}$. Each $\phi$ is called a local coordinates system. We consider here only cases where all the atlas are equivalent, \mie the diffemorphism are kept from one local coordinates system to the other.

Intuitivelly, a differentiable manifold is a set that locally behaves like $\mathbb{R}^n$.

\subsection{Tangent space}
On each point $p$ of a differential manifold $\mathcal{M}$ we write $C^\infty(p)$ the set of all smooth function from any neighborhood of $p$ into $\mathbb{R}$. The tangent space $T_p(\mathcal{M})$ is the subset of linear form over $C^\infty(p)$ satisfying the ``derivation'' Leibniz rule, \mie:
\EAIN
T_p(\mathcal{M}) \triangleq \Big\{ &X_p : f \in C^\infty(p) \rightarrow \mathbb{R},  \\ & \forall f,g \in C^\infty(p), \alpha \in \mathbb{R}, X_p(\alpha f + g ) = \alpha X_p(f) +X_p(g) \\ &\textrm{ and } X_p(fg) = X_p(f)g + f X_p(g) \Big\} \EAOUT
Intuitively, the tangent space defines all the possible directions at which a tangent to a curve of $\mathcal{M}$ in $p$ can pass.

The tangent space is a linear space. A basis can be built from the canonical basis $(x_1,...,x_n)$ of $\mathbb{R}^n$ using any local coordinates $\phi$ at $p$. The basis is denoted $(\dpartial{}{x_1}, ... , \dpartial{}{x_n} )$.

A vector field $X$ is simply the association of a vector of the tangent space to any point of the manifold:
\[ X: p \in \mathcal{M} \rightarrow X_p \in T_p \mathcal{M} \]

\subsection{Lie group and algebra}

A Lie group $\mathcal{G}$ is a differential manifold with a smooth group operation and inverse.  The neutral element  of the group is denoted by $1_\mathcal{G}$.
\newline\emph{In the case of spatial rotation, the Lie group is $SO(3)$}. \medskip

Using the group law, invariant vector fields can be produced by morphing a vector of the tangent space at $1_\mathcal{G}$ by all the left composition $L_g : h \in \mathcal{G} \rightarrow hg$. Details can be found in [Murray 93]. Therefore, the tangent space at $1_\mathcal{G}$ is isomorphic to the set of invariant vector fields. An invariant vector field is denoted by $X_w$ with $w \in 1_\mathcal{G}$ the generator.

This space $T_1 \mathcal{G}$  is called the standard Lie algebra associated with the Lie group and denoted by $\mathfrak{g}$. It inherits its vector-space structure from the tangent space, to which is added the algebraic structure coming from the Lie bracket operation, inherited from the vector field set. This operation being anectodic for this study, it is not described forward.
\newline\emph{In the case of spatial rotation, the Lie algebra is $\mathfrak{so}(3)$}. \medskip

From the standard Lie algebra, it is possible to define the exponential map from $\mathfrak{g}$ to a neighborhood of $1_\mathcal{G}$.  For any $w \in T_1 \mathcal{G}$, let $g_w: t \in \mathcal{R} \rightarrow g_w(t) \in \mathcal{G}$ denotes the integral curve of the invariant vector field $X_w$ generated by $w$ and passing through $1_\mathcal{G}$ at t=0. The exponential map of $w$ is defined from $g$ after unitary integration by $exp(w) = g_w(1)$, or for any $t$:
\[ \exp(t w) = g_w(t) \]
\emph{In the case of spatial rotation, the exponential map definitions fit}. \medskip

The exponential map is a diffeomorphism from a neighborhood of $0_\mathfrak{g}$ to a neighborhood of $1_\mathcal{G}$. This defines a local coordinate system around $1_\mathcal{G}$. Using the group law of $mathcal{G}$, this local coordinate system can be morphed to a proper atlas.

Moreover, if $\mathcal{G}$ is compact, the exponential map is surjective. In that case, the exponential map defines a global coordinate system, inherited from the vector space structure of $\mathfrak{g}$. It is called the canonical exponential coordinates.

\section{The exponential map is not everything}

Despite the topological origin, the exponential coordinates do not keep the topology of the initial space. In particular, the exponential map is not injective in general, which means that several coordinates correspond to one same point. Typically for $SO(3)$, the exponential coordinates are defined modulo $2 \pi$ and does not keep the symmetry of the group with a singularity in the neighborghood of the null rotation $I_3$ (the direction being degenerated when the angle is becoming null).

\subsection{Euler angles}
Other representation of $SO(3)$ exists. The first to be known are the Euler angle, which corresponds to a sequence of three elementary rotations of angle $a_i$, $i=1..3$, around three axes. Two types can be distinguished: the first when the rotations are performed around fixed axes. They can be written using the exponential map by:
\[ r(a_1,a_2,a_3) = e^{a_1 \hat{w_1}} e^{a_2 \hat{w_2}} e^{a_3\hat{w_3}} \]
where $w_i$, $i=1..3$ are three rotation axis.
The second type correspond to the rotations that are performed around axes that rotates with the transformation. In that case:
\[ r(a_1,a_2,a_3) = e^{a_1 \hat{w_1} + a_2 \hat{w_2} + a_3\hat{w_3}} \]
Note by the way that $e^{\hat w_1 + \hat w_2} \neq e^{\hat w_1}e^{\hat w_2}$ except in particular cases.

The most used rotation are the roll-pitch-yaw. It corresponds to the rotation of the first type, with $w_3 = (1,0,0)$ (roll, around the $X$ axis), $w_2 = (0,1,0)$ (pitch, around the $Y$ axis) and $w_1 = (0,0,1)$ (yaw, around the $Z$ axis). These angles are much used in the aerospace industry.

\subsection{Quaternions}

The quaternion are a way to get rid of the singularity of the exponential coordinates in 0 and of their non surjectivity modulo $2\pi$. Geometrically, the normalized quaternions correspond to the sphere $\mathbb{S}^3$ which is a submanifold of $\mathbb{R}^3$, while keeping the same topology than $\mathbb{S}^2$ for $\mathbb{R}^2$. They are defined from the complex numers $\mathbb{C}$ exactly like the complex numbers are defined from $\mathbb{R}$ using $\mathbb{C} = \mathbb{R} + \mathbb{R}i $, with $i^2 = -1$. We define the imaginery number $j$ such that $j^2 = -1$ and $ij = -ji$. By convenience, we denote by $k = ij$, that has the properties that $k^2=-1$, $jk = i$ and $ki=j$. The quaternion space $\mathbb{H}$ is then defined by:
\[ \mathbb{H} = \mathbb{C} + \mathbb{C} j 
= \mathbb{R} + \mathbb{R} i + \mathbb{R}j + \mathbb{R} k \]
The quaternions are equiped with the multiplicative law of $\mathbb{R}$. It is relatively easy to show that the inverse elements in $\mathbb{H}$ is:
\[ q^{-1} \triangleq \frac{\overline{q}}{||q||^2} \]
with the  conjugate of the quaternion $q=q_0 + q_1 i + q_2 j + q_3 k$ being $\overline{q} \triangleq q_0 - q_1 i - q_2 j -q_3 k$ and the norm being $||q||^2 = q \overline{q}$, that is to say the Euclidean norm of $\mathbb{R}^4$.

The quaternion space has many intersting property. The interest for the Euclidean motion representation is that it can embed the rotation group $SO(3)$ in its unitary sphere $\mathbb{S}^3$:
\[ \mathbb{S}^3 \triangleq \left\{ q \in \mathbb{H}, ||q|| = 1 \right\} \]
The sphere $\mathbb{S}^3$ is trivially a subgroup of $\mathbb{H}$. It is directly associated with $\mathfrak{so}(3)$ while preserving the group structure of $SO(3)$ using the simple map:
\[ (\theta,u) = (||w||,\frac{1}{||w||}) \repr r \in SO(3) \rightarrow q(r) = cos(\frac{\theta}{2}) + sin(\frac{\theta}{2})(u_1 i + u_2 j + u_3 k) \]
with $u = (u_1,u_2,u_3)$ the coordinates of $u$. It is possible thus teddious to verify that the group structures of $SO(3)$ and $\mathbb{H}$ fit. 

The reciprocal in the proper subspace of $\mathfrak{so}(3)$ is:
\[
\theta = 2 cos^{-1} (q_0),
\quad u = \left\{  \begin{array}{ll} 0, & \theta = 0, \\ \frac{1}{sin(\theta/2)} q_{1:3} & \theta \neq 0 \end{array}\right. \]
with $q_{1:3} = (q_1,q_2,q_3)$. The conditional equality depending of $\theta=0$ corresponds to the singularity of $\mathfrak{so}(3)$ around the zero rotation. Moreover, we can notice that both $q$ and $-q$ produce the same rotation. $SO(3)$ in fact corresponds topologically of the half sphere or projection plane $RP^3$.

\subsection{Summary of rotation representations}
The quaternion representation is of dimension $4$ with one constraint ($||q||=1$). It is therefore not minimal. However, it more adequatly captures the topology of $SO(3)$. In addition, it is equiped with a composition law corresponding to the composition of rotation, while being cheaper to compute numerically. Finally, the action of the linear map $q \repr r \in SO(3)$ on any $v \in \mathbb{R}^3$ can be computed directly from the quaternion using:
$ r(v) = q \tilde{v} q  $
where $\tilde v = v_1 i + v_2 j + v_3 k$. In many situations, the quaternions are the most adapted representation of $SO(3)$. The exponential coordinates have to be chosen when minimality is crucial, while $\mathbb{R}^{3\times3}$ might be more interesting when many vector multiplications are computed (typically when rotating a cloud of thousand of points).

\section{Rigid displacement $SE(3)$}

We now come back to the initial $SE(3)$ group, the set of all application in $\mathbb{E}^3$ that preserves the distance and the orientation. $SE(3)$ can be shown to be the composition of a pure rotation $r \in SO(3)$ and a pure translation $t \in \mathbb{R}^3$:
\[ SE(3) = \mathbb{R}^3 \times SO(3) = \{ (r,t), r\in SO(3), t \in \mathbb{R}^3 \} \]

\subsection{Homogeneous matrix representation}
Denoting by $m \repr (r,t)$ a rigid motion of $SE(3)$, its application on a point $p \in \mathbb{E}^3$ is:
\[ m(p) = r(p) + t \]
The application $m$ is therefore affine in $\mathbb{R}^3$. In can be transformed for convenient to a linear map to the cost of embeded it in the larger space $GL(4) \repr \mathbb{R}^{4\times4}$ by:
\[ M p = \BIN R & t \\ 0_{1\times3} & 1 \BOUT \BIN p \\ 1 \BOUT \]
where $M \in \mathbb{R}^{4\times4}$ is the homogeneous representation of $m \in SE(3)$, $R \in  \mathbb{R}^{3\times3}$ is the matrix representation of the rotation part of $m$, $t \in \mathbb{R}^3$ is the translation part of $m$ and $p \in \mathbb{R}^3$ is the vector representation of the point $m$ is applied to.

The matrix product fits to the composition operation of $SE(3)$, providing directly the group structure of $SE(3)$:
\begin{itemize}
\item if $m_1,m_2 \in SE(3)$, then $m_1 \circ m_2 \in SE(3)$. Moreover, the law is associative.
\item the identity of $SE(3)$ corresponds to $I_4$.
\item the inverge $m^{-1}$ of $m$ is represented by:
\[ M^{-1} = \BIN R^T & -R^T p \\ 0 & 1 \BOUT \]
\end{itemize}

\subsection{Pose-u-theta coordinates}

Like for $SO(3)$, the matrix representation of $SE(3)$ is convenient but not minimal: 16 components are necessary but are subject to 7 constraints, three for the $R$ part and 4 for the last row (these 4 last components are indeed trivial). Moreover, it is more convenient to express the coordinates as a vector space $\mathbb{R}^n$ ($n$ being intuitively equal to 6), where the neutral element is $0_n$ and where the group topology is closer to $\mathbb{R}$ than $GL(4)$.

Using the canonical exponential coordinates of $SO(3)$, we can directly propose the coordinates system $\mathbb{R}^3 \times \mathfrak{so}(3)$:
\[ m = (r,p) \repr \BIN p \\ w \BOUT \]
where $r \repr w$ is the exponential representation of the rotation part of $m \in SE(3)$. Like $\mathfrak{so}(3)$, this coordinates system has no group structure that fits the topology of $SE(3)$.

\subsection{Exponential coordinates}

This intuitive coordinates system is close to be the exponential coordinates of $SE(3)$ but is not exactly it. This means that their derivative does not fit with the tangent space to $SE(3)$, \mie to the velocity of rigid bodies. To obtain the exponential coordinates of $SE(3)$, the procedure is similar to the one performed in $SO(3)$. 

Let $m(t)$ be a curve in $SE(3)$. By analogy, consider the following matrix:
\EIN{nu} \dot{M}(t) M(t)^{-1} = \BIN \dot{R}(t) R(t)^T & \dot{p}(t) - \dot{R}(t) R(t)^T p(t) \\ 0&1 \BOUT \EOUT
We denote by $w(t)$ the angular velocity $\hat{w}(t) = \dot{R}(t) R(t)^T$. The last columns is then denoted by $v(t) = \dot{p}(t) + p(t) \times w(t)$. The pair $\nu(t) = (v(t),w(t)) \in \mathfrak{se}(3) = \mathbb{R}^3 \times \mathfrak{so}(3)$ can be identified to the tangent vector to the curve $m(t)$. It corresponds to the kinematic screw (``torseur cin\'ematique'' in French) of the rigid body moving following $m(t)$, expressed at the origin of the coordinates system of $\mathbb{E}^3$ in which $m(t)$ is expressed. See next subsection for details.

By integration of a constant kinematic screw $\nu = (v,w)$ on $[0,1]$, the exponential map is obtained.
\[ e^{\nu} =
\left\{ \begin{array}{cl}
 \BIN e^{w} &  \frac{1}{||w||}\Big( ww^Tv + (I-e^{w}) w \times v \Big) \\ 0 & 1 \BOUT,& \textrm{if } ||w||>0 \\
 \BIN I_3 &  v \\ 0 & 1 \BOUT,& \textrm{otherwise}
\end{array}\right.
\] 

Intuitively, the kinematic screw can be understood has representing a ``screw'' motion, \mie a pure rotation of angle $\theta$ around a fixed axis in $\mathbb{E}^3$ followed by a pure translation of length $d$ in the direction of this same axis. Such a screw motion is defined by six parameters (5 for the axis \meg 3 for a point $x$ on the axis and 2 for a  direction (normalized vector $u$) plus 1 for the pitch \mie the ration $h=d/\theta$ between translation and rotation, $d=\infty$ being a pure translation). Indeed, if we set:
\EAIN u \triangleq \frac{1}{||w||} w  \\ x \triangleq u \times v \\ h \triangleq w^T v \EAOUT
we obtain an equivalence (isomorphism) between the kinematic screw and the screw motion. This isomorphism prooves by the way the theorem of Chasles stating that any motion on a rigid body can be expressed as the motion of a screw, for a uniquely defined screw (that may typically not be attached to the rigid body but to an imaginary point).
See [Murray 94] for a detailed discution.

The exponential map is sujective into $SE(3)$. The inclusion of its image in $SE(3)$ is straightforward from its matrix structure. The covering is ensured by the compactness of $SE(3)$ but can also be constructively demonstrated by building the logarithm map:
\[ log: m = (r,p) \rightarrow (w, v) \]
with $w=log(r)$, $v = p$ when $||w||=0$ and $v = ||w|| \Big( ww^T + (I-e^w)\hat{w} \Big)^{-1} p$ otherwise.

\subsection{Movement of coordinates system in $SE(3)$}

Any rigid movement $m \in SE(3)$ displaces a coordinates system of $\mathbb{E}^3$ (\mie a point $\mathcal{O} \in \mathbb{E}^3$ and three orthonormal vectors of $\mathbb{R}^3$) into another coordinates system. Consider two coordinates systems of $\mathbb{E}^3$ denoted by their frames $\mathcal{F}_a$ and  $\mathcal{F}_b$. The coordinates of a point $p\in \mathbb{E}^3$ are denoted by $^ap$ in $\mathcal{F}_a$ and by $^bp$ in $\mathcal{F}_b$. We denote by $^am_b \repr \leftidx{^a}{M}{_b} \in \mathbb{R}^{4\times4}$ the rigid motion displacing the frame $\mathcal{F}_a$ into the frame  $\mathcal{F}_b$. In that case, we have:
\[ ^ap = \leftidx{^a}{M}{_b} \leftidx{^b}{p}{} \]
The notation follows the tensor notations. 

Consider now a fixed inertial frame $\mathcal{F_o}$ and a body frame $\mathcal{F}_b$ attached to a moving rigid object, such that the two frames match at $t=0$. The  position of any point $p$ attached to the rigid body through the time can be described by only giving the trajectory $^om_b(t)$ in $SE(3)$:
\[ ^op(t)  = \leftidx{^o}{M}{_b}(t) p_b\]
where $p_b = p_b(0)$ are the coordinates of the fixed position of the point $p$ in the body frame.

We say the $^om_b$ is the placement (\mie position and orientation) of the body $b$ in the coordinates system $o$.

\section{A first taste of rigid velocities}

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\chapter{Direct geometry} \label{sec:directgeom}

In the previous section, we have seen how rigid displacements can be represented. We now consider a more complex class of movements: the articulated rigid motion, \mie the considered system is composed of a finite set of rigid elements, each of them moving subject to some given  constraints imposed by the joints linking them. We consider here only the case of open kinematic chain (properly describe below described) and will discuss only quickly the case of kinematic loops later.  Like for $SE(3)$, we will discuss here the possible solution to numerically represent the motion of such systems and to compute the motion (position, velocities, etc) of each points of the system.

The most difficult part of the study has been done with $SE(3)$. This section is thus notably shorter.

\section{Kinematic tree}

We consider the graph structure describing the links between each rigid body: each node of the graph represents one rigid body and the edges of the graph represents the joints connecting two bodies together. A body can be connected to several other bodies through several joints. It is not connected to itself and only connected once to any other. Open kinematic chains are those for which there is no loops in the graph, \mie it is possible to selec a tree structure for the kinematic graph. Simple kinematic chain are reduced to a trivial tree (only one branch, each node has only one son and one father at maximum).

Two cases can be considered, that are mathematically the same but leads to two different interpretations of the root: the robot can be attached to the ground. In that case, the root of the tree, named the base link, is fixed. Or the robot can be free to move. The root of the tree is then arbitrarily selected. We say that the robot has a free flyer.
Both case are similar in the sense that a free-flyer robot can be seen as attached to a fixed ``ground'' body by a ``free-flyer'' joint; or alternatively a fixed robot is a free-flyer chain with the base body having infinite inertia.

In the following, we take the first convention: the base link is fixed, and a free-flyer robot is obtained by adding an artificial ``free-flyer'' link.

\section{Bodies}

Each body, represented by a node of the graph, is a rigid set of points. The body is associated with a body coordinates system, into which any point is described by a constant vector of $\mathbb{R}^3$. 

\section{Joints}

The joints are the moving pieces of the articulated rigid body. Each joint is attached two joints, one being the father $i$ and the second the son $i+1$. In general, the configuration $q_i$ of a joint is an element of a differentable manifold $\mathcal{Q}_i$ that uniquely defines the placement of the son body in the coordinates system of the father body:
\[ K_i: q_i \in \mathcal{Q}_i \rightarrow \leftidx{^a}{m}{_b}(q) \in SE(3) \]
For convenience, we generally rather consider a class of joint, caracterized by their $K_i : \mathcal{Q}_i \rightarrow SE(3)$ function. The joint linking body $i$ to body $i+1$ is then defined by its placement in the system $i$ along with its kinematic function $K_i$.

In all the relevant cases, $K_i$ is a smooth function and $\mathcal{Q}_i$ a compact Lie group. It is therefore possible to associate a global vector representation to $\mathcal{Q}_i$ and a Jacobian matrix to the tangent application to $K_i$. The standard position of the joint is given by the neutral element of the group $1_\mathcal{Q}$, expecting $K(1_\mathcal{Q}) = 1_{SE(3)}$.

The relative placement of body $i+1$ in the coordinate system of body $i$ is then given by:
\[ q_i \in \mathcal{Q}_i \rightarrow \leftidx{^i}{m}{_{i+1}}(q_i) = \leftidx{^i}{m}{_{i+1}^0} \  K_i(q_i) \]
with $\leftidx{^i}{m}{_{i+1}^0} = \leftidx{^i}{m}{_{i+1}}(1_\mathcal{Q}$ the placement of the joint in the coordinates system of body $i$.


\subsection{Revolute joint}

The most classical joint is the revolute joint: one degree of rotation around a fixed axis, typically the $Z$ axis. The configuration space of the joint is then $\mathcal{S}^1$ the unitary circle. Most of the time, the joint angle is bounded by an upper and a lower joint limit. The configuration space is then an interval of $\mathbb{R}$. The kinematic function $K$ is simply:
\[ K_i: q \in \mathbb{S}^1 \rightarrow \BIN \cos q & -\sin q & 0 & 0 \\ \sin q & \cos q & 0 & 0 \\ 0 & 0 & 1 & 0 \\ 0 & 0 & 0 & 1 \BOUT \]

\subsection{Prismatic joint}

Prismatic joint can translate (typically in an interval) along a given fixed axis, say $Z$. The configuration space is direcly $\mathbb{R}$. The kinematic function $K$ is trivially $K_i(q) = \big(I,(0,0,q)\big) \in SO(3)\times\mathbb{R}^3$.

\subsection{Free-flyer joint}

Free-flyer joints are configured by $SE(3)$ with their kinematic function being the identity on $SE(3)$. 

\subsection{Other joints}

Other joints can be found, even if very rarely used in robotics. Sperical joints allow free and symetrical rotations. Their configuration space is $SO(3)$, with their kinematics being $r \rightarrow (r,0_3)$. Very few efficient mechanisms exist to actuate such a joint. A similar effect is rather used by a sequence three revolute joints with concurent rotation axes. However, spherical joints are very often used for modeling purpose, for example for the model of the human body (typically, the hip joint), or for passive mechanisms.

The planar joint is a free 2D motion: two translations, one rotation. Its configuration space is $SE(2)$. The cylindric and helicoidal joints are a composition of on translation and one rotation with shared axis, the first one with free , the second with coupled rotation and translation motions.

\section{Configuration space}

The configuration space of the robot is typically the result of the Cartesian product of the configuration space of all the joints. Its reprensation is the cartesian product of the representation of the joint configuration spaces. The order of the terms in the Cartesian product only matters for the representation of the configuration space. It is purely arbitrary.
In the case of a simple kinematic chain, the only relevant order is the one given by the chain.
\[ \mathcal{Q} = \times \mathcal{Q}_i \]
For kinematic trees, the selected order should be compatible by the implicite partial order defined by the tree. The order in which the branches are explored is typically arbitrary and has to be documented.

When only minimal vector representation of the $\mathcal{Q}_i$ are used, a minimal vector representation of $\mathcal{Q}$ is obtained. The dimension of the vector $q$ is equal to the dimension of the manifold $\mathcal{Q}$.

\section{Direct geometry function}

We called the end effector of the robot one of the body of arbitrary importance (typically the one carrying the tool). 
For all this part, we can consider only simple chain without significant loss of generality. In that case, the end effector is the last body of the chain.

The robot direct geometry function (as said upper, often named direct, or forward, kinematic function in the litterature) is the function that maps the configuration space to the placement of the end effector in $SE(3)$:
\begin{align*}
 K: q = (q_0, ... , q_{n-1}) \in \mathcal{Q}  \rightarrow & \prod_{i=0}^{n-1} \leftidx{^i}{m}{_{i+1}^0} K_i(q_i) \\
&=  \leftidx{^0}{m}{_{1}^0} K_0(q_0) \leftidx{^1}{m}{_{2}^0} ...   \leftidx{^{n-2}}{m}{_{n-1}^0} K_{n-1}(q_{n-1})
\end{align*}

The direct geometry function $K$ can be represented as a function from the vectorial representation of $\mathcal{Q}$ to $\mathbb{R}^{4\times4}$.
In the case of all the joints that we considered upper, the components of the homogeneous matrix are polynoms of the components of $q$ and of sinus and cosinus of the components of $q$, with the coefficients of the polynoms depending on the placement of the joints in their reference body. The degrees of the polynoms are equal to the dimension of $q$.

The notion of end effector is arbitrary. In particular, the end effector can be a sub part of the last body. In that case, a last constant rigid move $\leftidx{^{n-1}}{m}{_n}$ is added to the geometry function:
\[ K(q) =  \leftidx{^0}{m}{_{1}^0} K_0(q_0) \leftidx{^1}{m}{_{2}^0} ...   \leftidx{^{n-2}}{m}{_{n-1}^0} K_{n-1}(q_{n-1}) \leftidx{^{n-1}}{m}{_n} \]

In the case of kinematic trees, several direct geometry functions are defined for each end effector attached to the end of each leaf of the tree.

\section{Denavit-Hartenberg parametrization}

The Denavit-Hartenberg method is a minimal parametrization of a revolute-prismatic kinematics chain. It is used to minimaly describe the relative joint placements $\leftidx{^{i}}{m}{_{i+1}^0}$. This parametrization was a de facto standard 10 years ago and is still often used (even if, now, the $SE(3)$ displacement is generally encoded directly using a standard representation).

Indeed, the static displacement $\leftidx{^{i}}{m}{_{i+1}^0}$ requires at least six parameters to be stored. However, the choice of the rotation around the axes of the joint $i$ and of the the joint $i+1$ are \emph{free} (translation in case of prismatic joints), in the sense that any static angles around these axes can be compensated to the cost of a translation of the joint configuration interval. The Denavit-Hartenberg parametrization therefore only needs 4 parameters to encode $\leftidx{^{i}}{m}{_{i+1}^0}$. 

The detail of how the static displacement can be computed from the Denavit-Hartenberg parameters can be found in [Murray93].

\section{Workspace}

The workspace $\mathcal{W}$ of the robot is the image space of the direct geometry function, \mie:
\[ \mathcal{W} = \Big\{ m \in SE(3), \textrm{ so that } \exists q \in \mathcal{Q}, K(q) = m \Big\} \]

In general, $\mathcal{W}$ is a compact non-convex subset of $SE(3)$. Its border are most of the time very difficult to compute explicitely.

% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\chapter{Analytical inverse geometry} \label{sec:anainvgeom}

The direct geometry maps the configuration space to the placement of the end effector. The map is in general not injective (several configuration corresponds to the same placement) and definitely not surjective: the robot workspace is not the entire world. However, programming a robot often comes back to placing its end effector to a given reference. The inverse geometry problem is defined by: given a reference placement in $SE(3)$, find one or all the configurations that matches this reference. The inverse maps $K^+$ the workspace to some non-empty  possibly non-trivial subset of the configuration space:
\[ K^+: m \in \mathcal{W} \rightarrow K^+(m) \subset \mathcal{Q} \]

The typicaly case of study is the non-redundant case: consider a robot with six joints. The problem is then properly balanced, with 6 constraints and 6 variables. 

In general, we do not know how to compute the inverse map explicitely. This was the subject of very extensive works of research in the 90's, that produce some efficient solutions in the case of non-redundant robot manipulator  $6 \times 6$ problem. These approaches where then extended to similar case, like in the case of one degree of redundancy (7 joints, 6 placement constraints).

\section{Overview of the possible methods}

The following description of the state of the art is taken from Juan Cort\`es PhD thesis [Cortes03].

\subsection{Substitution: geometrical view}

In most industrial applications, mechanisms are normally designed with
particular geometries which allow a closed-form analytical solution to the loop closure
equations. For instance, non-redundant serial manipulators often have the last three
revolute axes intersecting in a same point, which greatly simplifies the solution of the
inverse kinematics problem [Angeles 03].

\subsection{Substitution: algebraic view}

Two main approaches have been classically used: continuation and elimination (see [Nielsen 97] for a complete survey of these techniques). Polynomial continuation methods [Wampler 90] are purely numerical procedures able to find all possible solutions of the set of non-linear equations (in contrast to other numerical methods, such as Newton- Raphson, which converge to a single solution). These methods are based on homotopy techniques for gradually transforming a ``start'' system whose solutions are known to the system whose solutions are sought. These methods are robust and applicable to any set of equations. However, since they are iterative procedures, they are too slow in practice. Elimination approaches use one of the next algebraic methods: the Gr\"obner Basis method [Buchberger 82], which is an iterative variable elimination technique, or the resultant method [Gelfand 94], capable of eliminating all but one variable in a single step. In both cases, the elimination process normally leads to an univariate polynomial, relatively easy to solve [Pan 99]. The applicability of the Gr\"obner Basis method is mainly limited by its algorithmic complexity. Resultant methods can provide computationally fast techniques, but they require geometric intuition to nd (if possible) the formula for the resultant.

\subsection{Alternative methods}

Lately, interval methods for solving systems of non-linear equations have been proposed
as an alternative to continuation and elimination methods. They are based on interval
arithmetic [Moore 79, Hansen 92] and manipulate upper and lower bounds of variables.
Two main classes of interval-based methods have been applied in Robotics: those based
on the interval version of the Newton method [Rao 98, Castellet 98], and those based
on subdivision [Sherbrooke 93, Merlet 01, Porta 02]. They are completely numerical and
robust techniques. Although implemented techniques are still slow, recent improvements
are signifficantly increasing their efficacity [Porta 03].

\section{Geometric substitution}

We only treat here the geometric substitution case, with some simple example to give a broad insight of the approach. The geometric methods are not general, in the sense that they cannot be applied automatically but rather require the intuition of a robotic engenieer to chose the proper substitution. These methods were generalized in the case of 6-DOF revolute robots: the subsequent algebraic substitution are general (they work automatically for any revolute 6-DOF robots) but have not been generalized to other kinematic chains. 

\subsection{Simple planar 2R robot}

A 2R robot is a fixed kinematic chain composed of two revolute joints with parallel rotation axis. The configuration space is $\mathbb{S}^1  \times \mathbb{S}^1$. It therefore evoles in the plane orthogonal to the rotation axes. Two axes does not enable to control at the same time the two positions and the orientation. We therefore only consider the projection of the direct geometry function in the position space $\mathbb{R}^2$ (removing the orientation). The projected direct geometry map is:
\[ K: (q_1,q_2) \in \mathbb{S}^1  \times \mathbb{S}^1 \rightarrow \Big( l_1 cos(q_1)+ l_2 cos(q_1+q_2),l_1 sin(q_1)+ l_2 sin(q_1+q_2) \Big) \]
where $l_1$,$l_2$ are the length of the two bodies of the robot.

Now, considering a point $p \in \mathbb{R}^2$, the inverse geometry returns the configuration reaching this point. We denote $\rho = || p ||$ the distance of $p$ to the robot basis and $\alpha = \frac{1}{\rho} e_1^T p$ the angle of the direction from the robot basis to $p$.

By anthropomorphism, the first joint is called the ``shoulder'' and the second the ``elbow''. The configuration of the elbow is directly given by the distance from the robot to the point:
\[ q_2 = \]

The shoulder angle is given by the angle to the point:
\[ \]

\subsection{And the wrist?}

The same decomposition can be applied if two shoulder joints drives the robot orientation in the tridimensionnal space. 

If a set of joints are attached to the end effector to enable the control of the orientation, a third subproblem should be solved, to map the end effector desired orientation to the wrist angles. In that case, we first solve the wrist orientation, then the elbow lengthening and finally the reach orientation with the shoulder.

A more formal and very complete description of the geometrical substitution can be found in the book of [Murray94].


% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\chapter{Iterative optimization} \label{sec:numeric}

In the previous section, we have defined the inverse geometry problem and shown that there is no solution (yet) to solve it algebrically in the general case. Therefore, the only remaining solution is to approximate it numerically.

The inverse geometry problem comes back to find the root of a non-linear locally convex real-value function. Since $K$ is not real-value and is not null at the resolution of the problem, we have to define such a function to encapsulate our problem, for example:
\[ f: q \in \mathcal{Q}  \rightarrow \textrm{dist}(K(q),m^*)  \]
where $m^*$ is the reference position of the end effector in $SE(3)$ and dist is a distance (to be properly chosen) in $SE(3)$. Since $m^*$ might be out of the workspace, the function might never vanish. If such an instance of the problem might be implemented, it might be more interesting to search for the global optimum of the function rather than for its root (that will match, should the function vanishes). The inverse geometry problem is then rewritten as an optimization problem
\[  \min_{q \in \mathcal{Q}} f(q) \]

In this section, we will introduce the basics of the methods to solve this kind of problem. To simplify the presentation, we will focuse on the optimization in $mathbb{R}^n$, \mie in a given global coordinates system rather than directly in the manifold. Care has to be taken when coming back to more general manifolds (like $SE(3)$) to properly take into account the topology. We will focuse here on the optimization algorithms rather than on the analysis of the optimization problem itself (optimality conditions, caracterization, etc). A complete introduction to the optimization analysis can be found in [Hiriart-Urruty 11].

\section{Optimality condition}

We consider here only twice-differentiable $\mathcal{C}^2$ functions from a vector space $\mathbb{R}^n$ to $\mathbb{R}$:
\[ f: \mathbb{R}^n \rightarrow \mathbb{R} \]

\begin{definition}[Global minimizer]
The global minizer of $f$ is a vector $x^*\in\mathbb{R}^n$ if :
\[ \forall x \in \mathbb{R}^n, f(x^*) < f(x) \]
The minimum of $f$ is $f(x^*)$.
\end{definition}

Such a vector $x^*$ may not exist. Typically, the function might not be lower bounded, of the lower bound ($inf$ on the function) may not be reached or the minimum can be reached in several vector, possibly defining an implicit submanifold on $\mathbb{R}^n$.

Without any further hypothesis on the geometry of $f$, we do not have any condition to characterize $x^*$. We are reduce to study the local minization conditions.

\begin{definition}[Local (strict) minimizer]
A local strict minizer of $f$ is a vector $x^*\in\mathbb{R}^n$ such that there exist a neighborghood of $\mathcal{N}$ of $x^*$ where:
\[ \forall x \in \mathcal{N}, f(x^*) < f(x) \]
The value $f(x^*)$ is named the local minimum of $f$.
\end{definition}

Take care that the neighborghood can very well contain another local minimizer, \mie that there is a sequence of local minimizers of $f$ converging to $x^*$ (typically for functions that oscillates with diverging frequency when approaching to $x^*$.

The local minimization can intuitively be characterized by the derivatives of $f$. For additional conditions, it might be possible to guarantee that there exist only one local minimizer, \mie that a local minimizer is a global minimizer: if $f$ is strictly convex, any local minimizer is the global minimizer. Similarly, if we reduce the search to an open set of $\mathbb{R}^n$ where $f$ is convex, then a local minimizer on this set is a global minizer on this set. This is why the optimization methods presented below are often named ``convex optimization''.

A local minimizer is characterized by the following conditions:

\begin{theorem}[First order necessary condition]
  If $x^*$ is a local minimizer of $f$ \emph{\underline{then}} the gradient vanishes at $x^*$: \[\dpartial{f}{x}(x^*) = 0\].
\end{theorem}

The reciprocal is of course wrong: in general, a point where the gradient vanishes is a static point of $f$ (it might typically be a saddle point). The Hessian matrix can be used to distinguish between minimizers and static points.

\begin{theorem}[Second order necessary condition]
If $x^*$ is a local minimizer of $f$ \emph{\underline{then}} $\dpartial{f}{x}(x^*) = 0$ and the Hessian matrix is positive semidefinite: \[ \dpartial{f}{x}(x^*) = 0, \quad \ddpartial{f}{x}(x^*) \ge 0 \]
\end{theorem}

Here the Hessian is only guaranteed to be semidefinite.
This condition also holds for local non-strict minimizers, \mie if $x^*$ only satisfy $f(x^*) \le f(x)$ on a neighborghood. If the Hessian is definite positive it then characterized a necessary condition. 

\begin{theorem}[Second order necessary condition]
The vector $x^*$ is a local minimizer of $f$ \emph{\underline{if}} $\dpartial{f}{x}(x^*) = 0$ and the Hessian matrix is positive definite: \[ \dpartial{f}{x}(x^*) = 0, \quad  \ddpartial{f}{x}(x^*) > 0 \]
\end{theorem}

These three conditions can be easily demonstrated using the Taylor development of $f$, recalled in the following theorem.
\begin{theorem}[Taylor development]
Consider $f\in\mathcal{C}^2$. Then the developments of $f$ in $x$ are:
\begin{itemize}
\item (first order development) for any $p\in \mathbb{R}^n$, there exists $t\in\mathbb{R}$ such that:
\[ f(x+p) = f(x) + \dpartial{f}{x}(x+tp) p \]
\item (second order development) for any $p\in \mathbb{R}^n$, there exists $t\in\mathbb{R}$ such that:
\[ f(x+p) = f(x) + \dpartial{f}{x}(x) p + \frac{1}{2} p^T \ddpartial{f}{x}(x+tp)p  \]
\end{itemize}
\end{theorem}

\section{Overview of the algorithms}

The optimality conditions only use the information provided by the derivative of $f$. Similarly, the optimization algorithm will use this same information to search for the solution. 

All the algorithms start with an initial vector $x_0$, called the initial guess, and will iteratively improve this guess until it finally converges to a local optimum $x^*$. At each iteration $k$, all the algorithm roughly use the same schema: they first decide a direction of descent, \mie a direction $p_k$ of (tangent vector to) $\mathbb{R}^n$ where the next guess will be search; then the next vector $x_{k+1}$ is searched in this direction by choosing a step length $\alpha \in \mathbb{R}^+$ by solving the one-dimensionnal problem on the variable $\alpha$:
\EIN{stepmin} \min_{\alpha>0} f(x_k+\alpha p_k) \EOUT
The direction $p_k$ is chosen from a local model of $f$ around $x_k$, typically build using the derivative of $f$ at $x_k$, or using the derivatives at the previous $x_i$, $i\le k$. The step length $\alpha_k$ might be fixed (arbitrarily chosen from an apriori canonical unit of the system) ; or computed by dichotomy (line search algorithm) ; or chosen from the local model of the function (trust region algorithm).

The  iterative descente methods build a sequence of points $\Big(x_k \Big)_{k\in\mathbb{N}}$ with $\forall k, f(x_k) \le f(x_{k+1})$. Under some decrease conditions, the sequence converges to a local minimizer $x^*$. The convergence is assymptotic, which means that in a finite amount of time, only an approximation of $x^*$ is finally obtained in general. From the decrease conditions, a characterization of how quickly the algorithm converges toward the local minimizer can also be obtained.

\section{Descent direction}

\subsection{Gradient descent method}

The first method is to choose the descent direction given by the gradient of $f$ in $x_k$:
\[ p_k = -\frac{1}{|| \nabla f_k||} \nabla f_k \] 
with $\nabla f_k \triangleq \dpartial{f}{x}(x_k)$ the gradient of $f$.

The gradient is indeed the speepest descent direction. Indeed, for a direction $p$ unitary and a step length $\alpha$, the rate of change in the direction $p$ is given  by the derivative of $\alpha \rightarrow f(x_k+\alpha p)$. Using the Taylor second order development:
\[ f(x_k +\alpha p) = f(x_k) + \alpha p^T \nabla f_k + \frac{1}{2} \alpha^2 p^T \ddpartial{f}{x}(x_k+tp) p \]
for some $t\in\mathbb{R}$. The derivative of this function for $\alpha=0$ should be minimize for maximizing the descent, which directly gives $p^* = - \nabla f_k$.

The gradient is a proper direction descent, in the sense that for $\alpha$ sufficiently small, it decreases the value of $f$:
\[ \exists \alpha>0, f(x_k+\alpha \nabla f_k) < f(x_k) \]
This is prove using similar arguments than in the previous statement.

The gradient method converges linearly. This is stated by the following theorem.
\begin{theorem}[Rate of convergence of the gradient descent]
Consider a sequence $(x_k)_{k\in\mathbb{N}}$ generated by a gradient descent on $f$ with exact line search (\mie the minimum of \eq{eq:stepmin} is exactly reached for any $f$) converging to a point $x^*$ where the Hessian of $f$ is positive definite. Then, their exist $0<\rho<1$ and $N\in\mathbb{N}$ such that:\[ \forall k>N, f(x_{k+1}) < \rho f(x_k) \]
The rate $\rho$ can be computed from the eigenvalues of the Hessian:
\[ \rho = \Big( \frac{\lambda_n - \lambda_1}{\lambda_n + \lambda_1} \Big)^2 \]
\end{theorem}

The rate of convergence is linear, which is slow in general, and can typically be too slow for any application even for non singular cases. As explained in the book [LeMarechal06], the gradient descent should be considered only for theoretical study and should be forbiden for any applicative reason.

The study of the gradient descent on simple examples, like searching for the minimum of a quadric, reveal that the optimal step length is always at a point where the descent direction $p_k$ is orthogonal to the gradient computed at the new point $x_{k+1}$:
\[ \alpha^* \textrm{ is such that } p_k^T \nabla f(x_k + \alpha_k^* p_k) = 0 \]
The gradient descent therefore produces a zigzag trajectory to the optimum with $\frac{\pi}{2}$ rotations at each point $x_k$ of the sequence. A typical example used to exhibit the defect of the gradient descent is an optimization landscape where the optimum is at the end of non-straight deep canyon, for example the ``banana'' Rosenbrock function:
\[ b: (x,y) \in \mathbb{R}^2 \rightarrow b(x,y) =  (1-x)^2  + 100 (x^2 - y)^2 \]

The idea behind the Newton descent is therefore to use additional second-order knowledge about the geometry of $f$ that are not the speepest at the current point but move more directly toward $x^*$.

\subsection{Newton method}

The Newton\footnote{Newton was the first one to exhibit its eponymous method, for searching the root of a polynomial, but only in an unpublished booknote. He therefore shared the leadership with Raphson, who published in a similar context an equivalent formulation. Both names Newton or Newton-Raphson are used indenstigly used.}
 method approximate the function $f$ at $x_k$ by the quadric defined by the second order Taylor approximation (\mie the inexact development with $t=0$), given by:
\[ m_k: p \rightarrow f(x_k) + \nabla f_k^T p + p^T \ddpartial{f}{x}(x_k) p \]
The two functions $f$ and $x \rightarrow m_k(x-x_k)$ have the same value of their derivative of order 0 to 2 at $x_k$. 

This function has one global minimum, obtained when the derivative of $m_k$ vanishes and that gives the direction descent of the Newton method:
\EIN{newton} p_k = - \ddpartial{f}{x}(x_k)^{-1} \nabla f_k   \EOUT

The Newton method has a ``natural'' step length $\alpha = 1$. It provides a quadratic convergence to the local minimum, under the condition that $\ddpartial{f}{x}$ is positive definite at any point of the descent sequence. This is formalized by the following theorem.

\begin{theorem}[Rate of convergence of the Newton method]
Consider a function $f$ and a neighborghood $\mathcal{N}$ of a local minimizer $x^*$ of $f$ where $f$ is Lipschitz continuous. Then for any $x_0$ sufficiently close to $x^*$, $(x_k)_{k\in\mathcal{N}}$ converges quadratically to $x$: there exist $0<\rho<1$ and $N\in\mathbb{N}$ sufficiently so that:
\[ \forall k>N, || f(x_{k+1}) || < \rho || f(x_k) ||^2 \]
\end{theorem}
The complete proof is given in the book [Nocedal 06]. The convergence rate $\rho$ depends on the Hessian norm and Lipschitz coefficient: $\rho = \frac{L}{|| \ddpartial{f}{x}(x^*) ||}$.

The Lipschitz continuity around a point satisfying the second-order optimality condition guarantee the positive-definitness of the Hessian during all the descent. On the opposite, is the Hessian becomes non-positive (for example, for $x_0$ too far from $x^*$), the descent direction \eq{eq:newton} may not be a descent direction any more. In that case, the algorithm diverges, generally violently.

\subsection{Quasi-Newton method}

Very often in practice, the Hessian is to expensive too compute. Typically, the derivative are very often computed by finite difference:
\[ \dpartial{f}{x_i} (x_0) \approx \frac{f(x_0 + \epsilon x_i) - f(x_0)}{\epsilon} \]
with $x_i$ the $i^{TH}$ element of the cannonical basis and $\epsilon$ is a sufficiently small real number. The algorithmic cost of computing the gradient of a function from $\mathbb{R}^n$ to $\mathbb{R}$ is linear in $n$, and is $n^2$ for the Hessian, which might be unacceptable. Moreover, if it is often easy to get a good approximation of the gradient by finite difference, the Hessian approximation is often of much less quality, and the difference to its real value should be considered when studying the convergence rate.

The quasi-Newton methods are therefore the most-often used class of method. They choose the descent direction as:
\EIN{quasi} p_k = B_k^{-1} \nabla f_k \EOUT
where $B_k$ is a $n\times n$ positive definite matrix than converges to the Hessian:
\EIN{quasiB} \lim_{k\rightarrow+\infty} B_k = \ddpartial{f}{x}(x^*) \EOUT

Since we are not using the real Hessian, the rate of convergence is not as good as for the pure Newton descent. However, we keep a supra-linear convergence rate (much faster than the gradient).

\begin{theorem}{Rate of convergence of quasi-Newton methods}
Consider a sequence $(x_k)_{k\in\mathbb{N}}$ built using \eq{eq:quasi} such that \eq{eq:quasiB} holds. If $(x_k)$ converges to a local minimizer $x^*$ of $f$ with positive definite Hesssian, then the rate of convergence is superlinear, \mie for any $0<\rho <1$, there exist $N\in\mathbb{N}$ such that:
\[ \forall k>N, f(x_{k+1}) < \rho f(x_k) \]
\end{theorem}
While a linear rate converges to some linear assymptote, the superlinear becomes faster than any assymptote after sufficiently many iterations.

This last theorem is stronger and weaker than the one characterizing the Newton method. Stronger because it does not impose the restrictive condition of the Hessian positivity or continuity. Weaker because it is not able to ensure the convergence to any minimizer. The condition \eq{eq:quasiB} can even be reduced to:
\EIN{quasiB} \lim_{k\rightarrow+\infty} || \big( B_k - \ddpartial{f}{x}(x^*) \big) p_k || = 0 \EOUT
for $||p_k||=1$, that is to say, the Hessian has to be correctly approximated only in the descent direction.

Two classes of quasi-Newton methods can be distinguished. The first ones estimate the Hessian without any second order computation, by collecting the information of the geometry of $f$ while building the descent sequence. The second ones use an approximation of the Hessian, typically that is faster to compute, and that converges to the real Hessian close to the local minimizer.

Among the first ones, the most often used is the BFGS method (from the names of the inventors) that maintain during all the algorithm an approximation of the inverse Hessian (sparing at the same time the computation of the derivative and its inverse) by collecting the rate of variation of the gradient.

The next section will focuse on a typical example of the second class.

\subsection{Gauss-Newton method}

The Gauss-Newton method can be used to search for the minimizer of a least-square function, that is to say a function $f$ that is written as the square Euclidean norm of a vector function:
\[ \forall x \in \mathbb{R}^n, f(x) = \frac{1}{2} r(x)^T r(x) \]
where the function $r : \mathbb{R}^n \rightarrow \mathbb{R}^m$ is a vector-value function, called the residual function, that we want to minimize in the least-square sense.

Then, the gradient of $f$ is:
\[ \dpartial{f}{x}(x) = \dpartial{r}{x}^T(x) r(x) \]
and its Hessian is:
\[ \ddpartial{f}{x}(x) = \dpartial{r}{x}^T(x) \dpartial{r}{x}(x) + \sum_{i=1}^m \ddpartial{r_i}{x}(x) r_i(x) \]
where the real-valued function $r_i$ is the $i^{TH}$ component of $r$.

The so-called Gauss approximation is to neglect the second term of the Hessian. This approximation holds when the Hessian of the $r_i$ are small and when the residuals are small. 
Neglecting the second term has the advandage that both the gradient and the approximated Hessian of $f$ can be computed using only first order derivatives of $r$. The approximated Hessian is then simply $B_k =  \dpartial{r}{x}^T(x_k) \dpartial{r}{x}(x_k)$.

The quasi-Hessian is invertible as soon as there is enough independant residuals to ensure that $\textrm{rank} (\dpartial{f}{x}) = n$ (typically one $m>>n$).
In that case, the descent direction of the quasi-Newton method is:
\[ p_k = \big( \dpartial{r}{x}^T(x_k) \dpartial{r}{x}(x_k) \big)^{-1} \dpartial{r}{x}^T(x_k) r(x_k) \]
In this last definition, we can recognize the pseudo inverse of the Jacobian of the residuals:
\[ p_k = {\dpartial{r}{x}(x_k)}^{+} r(x_k) \]

\section{Modified direction and trust region}

Newton methods may diverge when the Hessian or its approximation are non-positive. It may converge to a non-strict local minimizer or even a static point if the Hessian is positive non-definite.

\subsection{Regularization}
To avoid the divergence, a quasi-Newton can be used with a modified Hessian that is guaranteed to be positive definite. The typical modification is to add the identity with a weighting parameter:
\EIN{mu} B_k = \ddpartial{f}{x}(x_k) + \mu I_n \EOUT
where $\mu$ is the Tikhonov regularization parameter that should be chosen large enough to ensure that $B_k$ is positive definite. When $\mu$ is so large that the Hessian term is neglectible in practice, the quasi-Newton step $B_k^{-1} \nabla f_k$ is equal to the gradient step with step length $1/\mu$. On the opposite, when $\mu$ is small enough so that the identity matrix is neglectible, the quasi-Newton step is equal to the Newton step. The parameter $\mu$ is then used to continuously switch between a gradient descent and a Newton descent.

Another interpretation of $\mu$ in the specific case of least-square functions is to penalize large step $||p_k||$. The use of $B_k$ will make a trade-off between a large step caused by a small singular value of the Hessian and a small step enforced by the penalization term. We will discuss this interpretation with more detail in the next chapter. 

\subsection{Trust region}
Finally, we only discuss in this section the line-search methods. The trust-region method also rely on a model $m_k$ of $f$ around $x_k$ but then decide at the same time the direction and the length by solving a subproblem based on the model $m_k$:
\[ \min_{||p_k|| \le \Delta_k} m_k(p_k) \]
It can be shown (see [Nocedal 06]) that the minimizer of this problem when $m_k$ is a quadric approximating $f$ in $x_k$ has a form equal to \eq{eq:mu} for some $\mu$ that have to be selected. Using this view on the problem, only $\Delta_k$ has to be chosen, $\mu$ being automatically chosen by solving the trust-region subproblem.

\subsection{Levenberg-Marquardt algorithm}
When the regularizer $\mu$ is needed, the complete algorith needs to determine two real coefficient at each iteration: $\alpha$ and $\mu$. The parameters are often adapted during the descent following some Heuristic. The most well known is the Levenberg-Marquardt algorithm.

In practice, the two parameters $\alpha$ and $\mu$ are modified depending on the ratio between the expected improvement of the current step and the improvement really obtained:
\[ \rho_k (\alpha,\mu) \triangleq \frac{ f(x_k) - f(x_k + \alpha_k p_k)}{ f(x_k) - m_k(\alpha_k p_k)} \]
First $\alpha_k$ is decided, typically by dichotomy from the unit step length $\alpha_k=1$ down to a minimal step length $\alpha_k = 10^{-6}$. The dichotmomy stops when a decrease of $f$ is obtained. If no decrease can be obtained, the direction is rejected, and the process start again with a bigger regularizer $\mu$. Now, for an acceptable $\alpha_k$, if $\rho_k$ is close to 1, the step is ideal and the optimization decrease as fast as possible. Inversely, if $\rho_k$ is close to 0 or even negative, the step is very poor or even diverge. In that case, a smaller trust region (\mie a bigger regularizer $\mu$) should be chosen. 

% ------------------------------------------------------------------------------
\section{Conclusion}

The methods that have been quickly presented in this section are converging very quickly to a local optimizer as soon as they are in a proper region of the input space, where the function is locally convex. This bassin of attraction of the local minimizer is very difficult to analytically or even numerically describe. However, outside of this bassin, the convergence is not guaranteed and is in any case very slow. Typically, outside the attraction bassin, the trust-region Newton methods loose their quadratic convergence to become as slow as the gradient. Moreover, the convergence is only on a local minimizer, that is not guaranteed to be global and not even to be interesting. Typically, when solving the inverse-geometry problem, the obtained configuration can typically not meet the desired end-effector placement, or even be very far from it.

All the challenge of numerical methods is to provide the proper intial guess. This is the only solution to ensure a quick and interesting convergence to a proper minimizer.

These numerical methods are working for optimizing a function from $\mathbb{R}^n$ into $\mathbb{R}$. Being given a norm on the image space of any vector function, they can be adapted to search for the minimum of the distance to a given element of the image space. 
We now have all the tools to numerically approximate a configuration of the robot that matches a given desired end-effector placement.



% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
% ------------------------------------------------------------------------------
\chapter{Numerical inverse geometry}\label{sec:numinvgeom}

The Gauss-Newton descent defined in the previous section gives a direct solution to search for the local minimum residulas of a vector to vector function $r: \mathbb{R}^m \rightarrow \mathbb{R}^n$. However, the inverse-geometry problem is rather written as a minimum-residuals of a function from a Lie group $\mathcal{M}$ of dimension $m$ to a Lie group $\mathcal{N}$ of dimension $n$, typically from the configuration space to $SE(3)$: 
$$ r: q \in \mathcal{Q} \rightarrow r(q) =  m(q)^{-1} m^*  \in SE(3) $$
where $m(q)$ is the placement of the end effector and $m^*$ is the reference placement that should be reached. Moreover, a proper norm on $\mathcal{N}$ should be chosen to define the least square.

Locally, the map $r$ can be identified to a map from a neighborghood of 0 in $\mathbb{R}^m$ to a neighborghood of 0 in $\mathbb{R}^n$. Intuitively, the Gauss Newton method should then be adapted, since it uses only local information on the residual maps. 

A first naive solution is to identify the residual map $r$ to the vector map from the local coordinates of $\mathcal{M}$ to the local coordinates of $\mathcal{N}$. When Lie groups are considered, this solution is valid since the local chart can be translated to a global chart. However, the global chart does not have nice global properties. In particular, it does not preserve the topology of the manifolds and therefore might badly interact with the iterative descent, adding an additional artificial layer of non linearity upon the initial problem, which slow down the algorithm. Rather, the local chart should be adapted around the candidate solution during the descent. Two aspects have to be considered: the representation of the candidate parameters in the input space $\mathcal{M}$ and the norm in the output space $\mathcal{N}$.

Let denote by $x_k \in \mathcal{M}$ a candidate minimum of the residual function $r$. We search a proper representation of the next candidate $x_{k+1}$. This can simply be done using the local exponentional representation centered on $x_k$. That is to say that $x_{k+1}$ is represented by the increment $d_k \in \mathbb{R}^m \repr T_{x_k} \mathcal{M}$  by:
$$ x_{k+1} \repr x_k e^{d_k} $$

Similarly the norm in the output space can be chosen as the Euclidean norm of the canonical representation of the residuals. 
$$ f(x_{k+1}) = \Big\| log \big( r(x_{k+1}) \big) \Big\|^2 $$
where $f: \mathcal{M} \rightarrow \mathbb{R}$ is the real-value function to be optimized by the Gauss-Newton algorithm.

%In the case of the inverse-geometry problem (\mie $\mathcal{N} = SE(3)$), the norm-2 in the tangent space $\mathfrak{se}(3)$ corresponds to the Froebenius norm of the homogeneous matrix representation:
%$$  \| log ( m ) \| = \| M \|

When the input space $\mathcal{M}$ is the special Euclidean groupo $SO(3)$ or a cartesian product of simple Lie Group with $SO(3)$, the quaternion representation (identified as the vector space $\mathbb{R}^4$) is often used in practice. A typical example of such problems is the problem known as ``structure from motion'' or simultaneous localization and mapping'', where a moving sensor (typically a camera) moves inside an unknowned environment while building a map of it. The optimization problem has then to be then rewritten as a constrained optimization problem:
$$ \min_{q \in \mathbb{R}^4} f(q) $$
$$ \textrm{subject to} \quad  q^T q = 1 $$
where $f$ is typically the maximum likelyhood of the camera position.
The constrained-optimization problem is out of the scope of this part and is not further detailed. In practice, the constrained might be neglected, each new candidate $q_{k+1}$ being normalized after each Newton iteration. This solution lacks of rigor but not of efficiency. 


% ##############################################################################
% ##############################################################################
% ##############################################################################
\part{Inverse kinematics}

The robot kinematics refers to the motion of the robot bodies with respect to the motion of the robot joints\footnote{As mentionned earlier, ``kinematics'' is often extended to designate also the robot geometry; in such a case, the reference to the velocity is made explicit by using the term ``differential kinematics''. In these notes, the word kinematics is exclusively used to designate the derivatives of the motion, \mie velocity and its derivatives.}. Most of the time, the word ``kinematics'' is limited to the robot velocity, but the same rules apply to the higher-order motion derivatives, in particular to the robot acceleration. The last case is often refered as ``second-order kinematics''. 

As for the geometry, the direct kinematics designates the function that maps the velocity of the joint (tangent to the configuration space) to the velocity of the robot bodies, typically the linear and angular velocities of the robot end effector (tangent to $SE(3)$). This is a proper closed-form function that is easy to calculate. The inverse kinematics is then the problem to find the reciprocal to this direct map, when it is defined, \mie, being given a reference velocity to executed by the robot end effector, what is the configuration velocities that accomplish this reference. Since we are at the level of the derivative, this problem is linear. It is therefore easier to study and to numerically solve than the inverse geometry problem. 

In particular, the resolution of the inverse geometry problem using Gauss-Newton descent can be rewritten as a sequence of inverse-kinematics resolution. 


% ##############################################################################
\chapter{Direct kinematics}

\section{The kinematic twist}

\subsection{Velocity vector field}

Consider a moving rigid object $B$ described by the position $^Bp \in \mathbb{R}^3$  of all its points in a coordinate frame attached to the object. The motion of $B$ is described with respect to a static coordinate frame $A$ by a trajectory in $SE(3)$:
$$ ^Am_B: t \rightarrow \leftidx{^A}{m}{_B}(t) $$
For any point $p$ of $B$, the position of $p$ in the coordinate frame $A$ is given by:
$$ ^Ap(t) = \leftidx{^A}{m}{_B}(t) (^Bp) = \leftidx{^A}{M}{_B}(t) ^Bp $$
with $M$ the homogeneous matrix representation of $m$. Each point $p$ then defines a trajectory in $\mathbb{E}(3)$, that can be derivated. The time derivative is the velocity of the point $p$ expressed in the coordinate system $A$ and denoted by $v$:
$$ ^Av_p(t) =  \leftidx{^A}{\dot p}{}(t) $$
The velocities at every points $p$ for a given (fixed) time $t$ defines a vector field. Using the homogeneous representation of $^Am_B$, the coordinates of $v$ in $A$ are easily expressed:
$$ ^Av_p(t) = \dot{ \leftidx{^A}{M}{_B}}(t) \leftidx{^B}{p}{} =  \dot{ \leftidx{^A}{M}{_B}}(t) \leftidx{^A}{M}{_B}^{-1}(t) \leftidx{^A}{p}{} = \leftidx{^A}{\hat \nu}{_{AB}}(t)  \leftidx{^A}{p}{}  $$
where $^A\nu_{AB} = ( \leftidx{^A}{v}{_B},\leftidx{^A}{w}{_B} )$ is the twist relative to the frames $A$ and $B$ expressed in the coordinate system $A$, and defined in \eq{eq:nu} and $\hat .$ is the operator passing from the vector representation to the matrix representation of the Lie algebra. In particular, the $v$ part of the twist corresponds to the velocity of the point of $B$ that passes by the origin of $A$ at time $t$ (thus making logical to use the notation $v$ both for the velocity vector field and for the first part of the twist).  The twist $^A\nu_{AB}$ corresponds to the classical definition of the twist in mechanics (``torseur cin\'ematique'' in French) expressed at the origin $A$. The first part $v$ is called the linear velocity, $w$ being the angular velocity.



\subsection{Instantaneous twist}

When defining the twist, we have chosen to look at the product $\dot{m} m^{-1}$. This is a convention. We can consider the commutation of the product instead. This corresponds to the velocity of a pont $p$ but expressed in the basis of the coordinate system $B$ and denoted by $^Bv$:
$$ ^Bv(t) = \leftidx{^A}{m}{_B}(t)^{-1} \leftidx{^A}{v}{p}(t) = 
\leftidx{^A}{m}{_B}(t)^{-1} \dot{\leftidx{^A}{m}{_B}}(t) \leftidx{^B}{p}{} $$ 
Similarly, we define $\leftidx{^B}{\nu}{_{AB}}$ the twist expressed in the body coordinate system by:
$$ \leftidx{^B}{\hat \nu}{_{AB}} =\leftidx{^A}{m}{_B}^{-1} \dot{\leftidx{^A}{m}{_B}}$$
The velocity of any point $p$ in the body system is given by:
$$ ^Bv(t) = \leftidx{^B}{\hat \nu}{_{AB}}(t) \leftidx{^B}{p}{} $$
The twist in $B$ is defined outside of any world reference and is therefore named the instantaneous twist.

\subsection{Twist actions}

From the above two definitions, we have the following simple relations between the two twist representations:
$$ \leftidx{^B}{\hat \nu}{_{AB}} = 
\leftidx{^A}{M}{_{B}}^{-1} \ 
\leftidx{^A}{\hat \nu}{_{AB}} \ 
\leftidx{^A}{M}{_{B}}
$$
This bilinear form in $^Am_B$ can be reduced using the bilinear property of the cross product hidden inside $\nu$:
$$ \leftidx{^A}{\nu}{_{AB}} = \BIN \leftidx{^A}{R}{_B} & \leftidx{^A}{\hat p}{_B} \leftidx{^A}{R}{_B} \\ 0 & \leftidx{^A}{R}{_B} \BOUT  \leftidx{^B}{\nu}{_{AB}}$$
with $^AM_B = ( \leftidx{^A}{R}{_B},  \leftidx{^A}{p}{_B} )$ denoting respectively the rotation and translation part of $^AM_B$.

{\footnotesize
\begin{proof}
First recall that we have:
$$M^{-1} = \BIN R^T & -R^T p \\ 0 & 1 \BOUT$$
Then:
\begin{align} \leftidx{^A}{\hat \nu}{} &= \BIN R^T & -R^T p \\ 0 & 1 \BOUT 
\BIN ^B\hat w & ^Bv \\ 0 & 1 \BOUT
\BIN R & p \\ 0 & 1 \BOUT 
\\
&=
\BIN R^T \  \leftidx{^B}{w}{}\ R & R^T \ \leftidx{^B}{v}{} + R^T \  \leftidx{^B}{\hat w}{}\  p \\ 0 & 0 \BOUT 
\\
&=
\BIN \hat{} (R\ \leftidx{^B}{w}{})  & R^T \ \leftidx{^B}{v}{} -   R^T p \  \leftidx{^B}{\hat w}{} \\ 0 & 0 \BOUT 
\end{align}
using the fact that $R \hat{w} = \hat{} (R\ \leftidx{^B}{w}{}) R$ (bilinearity of the cross product). The last equality is finaly reduced to the vector form to give the expected result. 
\end{proof}
}

The twist transformation matrix is denoted by $^AX_B$. It transforms the twist expressed at the origin of the system $A$ to the twist expressed at the origin of the system $B$. If the two frames of $A$ and $B$ are aligned, the transformation corresponds to a change of application point of the twist. 

Geometrically, the application $X$ corresponds to the action of the group $SE(3)$ on the Lie Algebra $\mathfrak{se}(3)$. See [Murray94] for a detailed discussion on Lie actions.

\subsection{Velocity vector field}
In particular, the twist can be expressed at any point $p$ of the rigid body $B$ using the basis of the system $A$. In that case, we recover the velocity vector field expressed in the frame $A$:
$$ ^Av_p = \leftidx{^A}{v}{_{AB}} + \leftidx{^A}{p}{} \times \leftidx{^A}{w}{_{AB}} $$
We denote by $L_p(t)$ the vector field that at any point $p$ fixed in the world (that is to say defined by a constant $^Ap$ associates $^Av_p(t)$ the velocity of the particule of the body passing by $p$ at time $t$. This corresponds to the Eulerian specification of the flow (which is rigid in this case) of particules attached to the body $B$. Intuitively, in corresponds to the point of view of a observer fixed with respect to a ``inertial'' world frame $A$ and looking at the flow passing at a specific point.

On the opposite, the instantaneous twist defines another vector field, defined by:
$$ ^Bv_p = \leftidx{^B}{v}{_{AB}} + \leftidx{^B}{p}{} \times \leftidx{^B}{w}{_{AB}} $$
We denote by $E_p(t)$ the vector field that at any point p fixed in the body (\mie defined by a constant $^Bp$) associates $^Bv_p(t)$. This corresponds to the Lagrangian specification of the flow field, and intuitively matches the point of view of an observer attached to the body and looking to the velocity of one point of the body as it moves through time.

\subsection{Twist sum}

The twists are defined in $\mathfrak{se}(3)$ which is a vector space. Two twists expressed in the same coordinate system can then be summed. Consider the case of two rigid bodies $B$ and $C$ moving in relative to a frame $A$, where the motion of $B$ is described with respect to $A$ by $^Am_B$ and the motion of $C$ is defined with respect to $B$ by $^Bm_C$. Then the twist describing the velocity of $C$ relative to $A$ is given by:
\begin{align}
 ^A\nu_{AC} &= \leftidx{^A}{\nu}{_{AB}} + \leftidx{^A}{\nu}{_{BC}} \\
 ^A\nu_{AC} &= \leftidx{^A}{X}{_B} \big( \leftidx{^B}{\nu}{_{AB}} + \leftidx{^B}{X}{_C} \ \leftidx{^C}{\nu}{_{BC}}  \big) \end{align}

\section{From the kinematic tree to the kinematic direct map}

\subsection{Joint Jacobian}

Recall that the joint geometry map $K_i$ is a function from the joint configuration Lie group $\mathcal{Q}_i$ to $SE(3)$. The map can be derivated using the local vector space structure of the input and output manifolds. We denote by $J_i$ the derivative of $K_i$ at the configuration $q$:
$$ J_i(q): v_q \in T_q\mathcal{Q} \rightarrow \nu = J_i(q) v_q \in \mathfrak{se}(3) $$
where $v_q$ is the velocity in the configuration space (formally, a vector of the tangent space to $\mathcal{Q}$ at $q$) and $\nu$ is the kinematics twist generated by the joint (formally, a vector of the tangent to $SE(3)$ at $K_i(q)$). The map $J_i(q)$ is the tangent map to $K_i$ at $q$\footnote{The tangent map to $f : \mathcal{M} \rightarrow \mathcal{N}$ at $m \in \mathcal{M}$  is the only map $T_mf : T_m\mathcal{M} \rightarrow T_{f(m)}\mathcal{N}$ so that for any smooth function $g$ from a neighborghood of $f(m)$ to $\mathbb{R}$ and any tangent vector $\dpartial{}{x} \in T_m\mathcal{M}$ , we have $(T_mf \dpartial{}{x})g = \dpartial{}{x} (g \circ f)$.}. It is linear in $v_q$. It is often abusively referred as the Jacobian of the joint, while the Jacobian should stance for the derivative of the map linking a representation of $\mathcal{Q}_i$ to a representation of $SE(3)$, and we will follow the same abusive name in the remaining of the document.

From the joint Jacobian, the joint direct kinematics map is defined by:
$$ (q,v_q) \in T_q(\mathcal{Q}_i)\times\mathcal{Q}_i \rightarrow \nu = J_i(q) v_q \in \mathfrak{se}(3) $$
The twist $\nu$ is the rigid velocity of the body attached to the output of the joint with respect to the local coordinate system of the joint, typically attached to the previous body in the kinematic tree. It can be expressed in any coordinate system $A$. We make the expression explicit as $^A\nu$ and $^AJ_i$. Most of the time, it is expressed in the local coordinate system chosen to express $K_i$. By abuse, we denote this default expression by $J_i= \leftidx{^i}{J}{_i}$.

\subsection{Examples of joint}
The revolute joint around the arbitrary axis $Z$ has the following simple constant Jacobian:
$$ J_i(q) = J_{R_z} = (0,0,0,0,0,1) $$
Similarly the prismatic joint of axis $Z$ has the following constant Jacobian:
$$ J_i(q) = J_{T_z} = (0,0,1,0,0,0) $$
In both case, the configuration velocity can be considered as the configuration time derivative $v_q = \dot q$. Finally, the free-flyer joint (that is imposing no constraint on the joint) has its Jacobian equal to the identity:
$$ J_{ff} = I_6$$

\subsection{Robot direct kinematics}

\subsection{Kinematics map}
Recall that the direct geometry of the joint $i$ is expressed in a coordinate system local to the joint and expressed with respect to the output of the previous joint by a constant rigid displacement $^im_{i+1}^0$. The direct geometry map of the robot is then:
\[ K: q \rightarrow  \leftidx{^0}{m}{_{1}^0} K_0(q_0) \leftidx{^1}{m}{_{2}^0} ...   \leftidx{^{n-2}}{m}{_{n-1}^0} K_{n-1}(q_{n-1}) \leftidx{^{n-1}}{m}{_n} \]
Consider now a curve $q(t)$ in the robot configuration space $\mathcal{Q}$. The curve of the robot end effector $^0m_n(t) = K(q(t) \in SE(3)$ can be derivated easily using the joint Jacobians. The robot end effector is then:
\[ (q,v_q) \rightarrow  
\sum_{i=0}^{n-1} \leftidx{^0}{X}{_i} J_i(q_i) v_{q_i} 
\]

\subsection{Robot Jacobian}
By identification, the robot Jacobian at $q$ is the following tangent map:
$$ J(q) = \sum_{i=0}^{n-1} \leftidx{^0}{X}{_i} J_i(q_i) $$

\subsection{Elements of algorithm}
Algorithmically, the direct kinematics and the Jacobian are computed by a backward loop on the kinematic tree, from the leaf representing the considered end effector.  At each iteration $i$ (from $n-1$ downto $0$) of the loop, we maintain the twist expressed in the local frame of joint $i$ and the corresponding Jacobian:
$$ ^i\nu_{i:n} = \leftidx{^i}X{_{i+1}} \ \leftidx{^{i+1}}\nu{_{i+1:n}} + \leftidx{^i}{J}{_i}(q_i) v_{q_i} $$
$$ ^iJ_{i:n} = \leftidx{^i}X{_{i+1}} \ \leftidx{^{i+1}}J{_{i+1:n}} + \leftidx{^i}{J}{_i}(q_i) $$
where $^i\nu_{i:n}$ is the relative twist of the current body $i$ and the end-effector, expressed in the system $i$ and $^iJ_{i:n}$ the $n-i+1$ columns corresponding to the explored $n-i+1$ nodes of the kinematics tree. The action matrix $X$ is simply computed from the joint geometry function $^im_{i-1} = K_i(q_i)$. The same backward loop would typically (but not necessarily) compute the robot geometry $K(q)$.


% ##############################################################################
\chapter{The pseudo inverse}

From the two previous chapters, we can interpret the  Gauss-Newton descent as a succession of pseudoinverse of the robot Jacobian $J(q_k)^+$, where $q_k$ is the current candidate configuration. Up to now, the pseudoinverse was not properly defined and was only limited to the non-general case where $J^TJ$ is invertible, which is clearly not true in general (this square matrix being only positive and sometime non-definite). In this chapter, we properly define the pseudoinverse and link it to the linear least-square problem.

\section{Moore-Penrose}

The pseudoinverse is formally defined by the four rules of Penrose, from which the existence, unicity and a long list of properties of this operator can be established. In this book, we will mostly see the pseudoinverse through the scope of the singular-value decomposition, that eases a lot (but sometime limits) its understanding. 

\subsection{Definition}

The pseudoinverse $X$ of a matrix $A \in \mathbb{R}{n\times m}$  is defined by the four following rules:
\EIN{A+1} AXA = A \EOUT
\EIN{A+2} XAX = X \EOUT
\EIN{A+3} AX \textrm{ is symmetrical} \EOUT
\EIN{A+4} XA \textrm{ is symmetrical} \EOUT

The matrix $A$ is possibly non invertible or even non square. We will show in the following that $X$ following these four rules always exists and is unique. It is denoted by $A^+$ (sometimes by $A^\dagger$ or $A^\#$).

\subsection{Case of invertible matrices}
In the case where $A$ is invertible, it is trivial to check that $A^{-1}$ respects the four rules and therefore $A^+ = A^{-1}$. Indeed, the pseudoinverse can be seen as a generalization of the inverse to any matrix. 

We denote by $N(A)$ the kernel (or null-space) of $A$, $N(A)^\perp$ its supplementary space ($N(A) \oplus N(A)^\perp$) and $R(A)$ the range space of $A$:
\begin{align}
\forall x \in N(A), \quad& Ax=0 \\
\forall x \in N(A)^\perp, \quad& Ax=0 \Rightarrow x=0 \\
\forall y \in R(A),\quad& \exists x\in N(A)^\perp, Ax=y
\end{align}
Then, the linear map $A$ limited to $N(A)^\perp \rightarrow R(A)$ is invertible, and its inverse matches with the pseudoinverse limited to $R(A) \rightarrow N(A)^\perp$ (the proof is left as an exercice).

\subsection{Proof of unicity}
The existence of $A^+$ is not trivial from the Moore-Penrose definition. We left the proof for the next section. The unicity is however direct. Suppose that two matrix $X$ and $Y$ respect the four rules. Then:
$$ X = XAX = XX^TA^T = XX^TA^TY^TA^T = XAXAY = XAYAY $$
In the last equality, the role of $X$ and $Y$ are symmetrical. The same can be done while inverting the two matrices:
$$ Y = YAY = A^TY^TY = A^TX^TA^TY^TY = XAYAY = X $$


\section{Singular-value decomposition}

The previous section formally defines the pseudoinverse. We will now give a constructive property of the pseudoinverse using the singular value decomposition. The full understanding of the pseudoinverse cannot be limited to this constructive definition, but the properties of the SVD help a lot to established many results linked to the pseudoinverse.

\subsection{Definition from the Eigen decomposition}

First, recall that a symmetric matrix $S \in \mathbb{R}^{n\times n}$ is diagonalizable in $\mathbb{R}$ with by an orthogonal matrix:
$$ S = U \Lambda U^T $$
with $U$ orthogonal, \mie $UU^T = I$ and $\Lambda$ the Eigen diagonal matrix.

Consider now a matrix $A \in \mathbb{R}^{n \times m}$. We denote by $U,\lambda$ the Eigen decomposition of $AA^T$. The Eigen values are denoted by $\Lambda = \textrm{diag}( \lambda_1 ... \lambda_n )$. We suppose in all the following that the Eigen values $\lambda_i$ are sorted. The square matrix $AA^T$ is positive ($\forall x \in \mathbb{R}^n, x^T(AA^T)x = (A^Tx)^T A^Tx \leq 0$) and therefore all Eigen values are positive or null. We denote by $r$ the rank of the matrix. From the positive condition, we have $\forall i=1..n, \lambda_i =0 \iff i>r$.

We define the singular values of $A$ to be the square-root of the Eigen values:
\[ \sigma_i \triangleq \sqrt{\lambda_i} \]
We define the right singular vectors by:
\[ \forall i\leq r, \quad v_i = \frac{1}{\sigma_i} A^T u_i \]
where $u_i$ is the Eigen vector corresponding to $\lambda_i$. It is easy to check that the family $(v_i)_{i=1..r}$ is orthonormal:
\[ v_i^T v_j = \frac{1}{\sigma_i \sigma_j} u_i AA^T u_j = \frac{\sigma_j^2}{\sigma_i \sigma_j} \delta_{ij} = \delta_{ij} \]
where $\delta_{ij}$ is 1 when $i=j$, 0 otherwise.

The family $(v_i)_{i=1..r}$ is augmented of any basis of $n-r$ vectors of the supplementary space to give a orthogonal matrix $V$. Similarly, we define $\Sigma \in \mathbb{R}^{n \times m}$ the matrix whose diagonal coefficients are the $\sigma_i$ and that is null otherwhere.

The triplet $U,\Sigma,V$ is called the singular value decomposition of $A$. It is written:
\[ A = U \Sigma V^T\]
The bases $U$ and $V$ are respectivelly called the left and right singular basis. The singular value is often rewritten to make the zero of the diagonal of $\Sigma$ explicit. Denoting by $U_1$ (resp. $U_0$) the Eigen vectors of $AA^T$ of non null (resp. null) Eigen value, and $V_1$ (res. $V_0$) the corresponding right singular vectors, and by $\Sigma_1$ the square diagonal matrix of non null singular values, we can write the sparse decomposition:
\[ A = \BIN U_1 & U_0 \BOUT \BIN \Sigma_1 & 0 \\ 0 & 0 \BOUT \BIN V_1 & V_0 \BOUT^T = U_1 \Sigma_1 V_1^T \]

With the convention that the singular values are taken positive and sorted, the singular decomposition is unique when the singular values are all different. Otherwise, any choice of the basis of the space span by at least two equal singular value respects the definition.

\subsection{Constructive proof of existence of the pseudo inverse}

Using the SVD, the pseudoinverse of $A$ can be easily build:
$$ A^+ = V_1 \Sigma_1^{-1} U_1^T $$
It is immediate to check that this matrix complies with the four conditions of Moore-Penrose. Since the pseudoinverse is unique, this gives a constructive definition of the pseudoinverse.

\section{Some properties}

\subsection{Range, kernel and projectors}
The SVD reveals the intrinsic structure of the decomposed matrix. In particular, the bases of the null and range spaces are obtained. We have:
$$ N(A) = V_0$$
$$ R(A) = U_1$$
$$ N(A)^\perp = R(A^T) = V_1 $$
$$ R(A)^\perp = N(A^T) = U_0$$

Moreover, the pseudoinverse provides a simple expression of the projectors in these spaces:
$$ P_{N(A)} = V_0 V_0^+ = I - A^+ A $$
$$ P_{R(A)} = U_1 U_1^+ = A A^+ $$

\subsection{Rank, full rankness}

The rank of $A$ can be defined indifferentially as the number of independant row or column vectors. From the SVD, it is clear that row or column definitions are equivalent and corresponds in fact to the number of non null singular values. 

The matrix is full-row rank if its rows form a free family, \mie if its rank is equal to its number of rows: $r=n$. 

The matrix is full-column rank if its columns form a free family, \mie if its rank is equal to its number of columns: $r=m$. 

Abusively, it is said to be full rank when it is full-row rank or full-column rank.

\subsection{Construction from the square} % A+ = (A'A)+ A'
The pseudo inverse of $A$ respects the following properties:
\EIN{AAA} A^+  = A^T (AA^T)^+  = (A^TA)^+ A^T \EOUT
To proove, simply check that both $A^T (AA^T)^+$ and $(A^TA)^+ A^T$ respects the Moore-Penrose conditions. The equality then follows since the pseudoinverse is unique.

\medskip
When $A$ is full-row rank, $AA^T$ is invertible and therefore its inverse is equal to its pseudoinverse. We have then that:
$$ A^+ = A^T(AA^T)^{-1} \quad \textrm{[\emph{if and \underline{only} if }} A \textrm{\emph{ is full-row rank}]}$$
This property gives another constructive property of the pseudoinverse. However, this is not a unconditional definition. The property is very often mistakenly used, while it only holds when $A$ is full-row rank. 

Similarly, when $A$ is full-column rank, we have:
$$ A^+ = (A^TA)^{-1} A^T  \quad \textrm{[\emph{if and \underline{only} if }} A \textrm{\emph{ is full-column rank}]}$$

In general, only the (non-constructive) property \eq{eq:AAA} holds.

\section{Other generalized inverses}

It is possible to define other generalized inverses of a matrix $A$ that respects only some of the four Moore-Penrose conditions. The properties and characterizations of the matrices respecting any combination of the four rules are described in detail in the reference book [BenIsrael03]. In particular, the so called-weighted inverse only respects the two first properties. We denote by $L \in \mathbb{R}^{n \times n}$ and $R \in \mathbb{R}^{m \times m}$ two symmetric definite positive matrices and by $\sqrt{L}$ and $\sqrt{R}$ their (non-uniquely defined) square-root such that $L=\sqrt{L}^T\sqrt{L}$ and $R=\sqrt{R}^T\sqrt{R}$. 


The right-weighted inverse of $A$, denoted by $A^{\#R}$ is defined by:
$$ A^{\#R} = \sqrt{R}(A\sqrt{R})^+ = RA^T(ARA^T)^+ $$
The right-weighted inverse verifies the three first rules of Moore-Penrose.  However, in genteral, we do not have the last one but rather:
$$ A^{\#R} A R = (A^{\#R} A R)^T $$
Following the notation of [BenIsrael03], it is said a $\{1,2,3\}$ generalized inverse.

The left-weighted inverse of $A$, denoted by $A^{L\#}$ is defined by:
$$ A^{L\#} = (\sqrt{L}A)^+\sqrt{L} = (A^TLA)^+A^TL $$
The left inverse respects the rules 1,2 and 4. But, instead of the third rule, we have:
$$ L A A^{L\#}  = (L A A^{L\#})^T $$

The $L-$left $R-$right weighted inverse of $A$ is defined by:
$$ A^{L\#R} = \sqrt{R}(\sqrt{L}A\sqrt{R})^+\sqrt{R} $$
It only respect the two first rules and instead of the two last, we have:
$$ A^{L\#R} A R = (A^{L\#R} A R)^T $$
$$ L A A^{L\#R}  = (L A A^{L\#R})^T $$

% TODO: can we proove that all (1,2) inverses are of this kind ?


\section{Unconstrained quadratic programing}

One of the major interest of the pseudoinverse is that it provides the solution to the linear least square problem.

\subsection{Definition}

\subsubsection{Quadratic formulation}
First of all, a quadratic problem of the variable $x\in\mathbb{R}^m$ is defined by:
$$ \min_{x\in\mathbb{R}^m} \frac{1}{2} x^T H x - g^T x $$
where $H\in\mathbb{R}^{m\times m}$ is a symmetric matrix and $g\in\mathbb{R}^m$ a vector (the notation stances for $H$ the Hessian, and $g$ the gradient, with respect to the Newton step resolution). The problem does not have any solution if $H$ is non positive (in such a case, any negative Eigen vector can leads to an arbitrarily large negative value). We therefore considere $H$ to be positive. When $H$ is non definite (positive), there is an infinite number of solution along the zero Eigen vectors. In such a case, we are often interested by the least-norm solution $||x||$.

\subsubsection{Linear least square}
A particular quadratic problem arrises when $H=A^TA$ and $g=A^Tb$. In that case, the problem is rewritten:
$$ \min_{x\in\mathbb{R}^m} || A x - b || $$
with $A \in \mathbb{R}{n \times m}$ any rectangular matrix and $b\in\mathbb{R}^n$ any vector. When $A$ is not full-column rank (then $H=A^TA$ is positive non-definite), there exists a infinite number of solutions, called the least-square solutions. Among those solutions, we are interested by the solution of minumum norm, or minimum-norm least-square solution.


\subsection{Least-square inverse}

The minimum-norm least square solution $x^*$ is uniquely exists and is given by the pseudoinverse:
$$ x^* = A^+ b $$

\begin{proof}
The vector $b$ can be decomposed as $\tilde b = R(A) b$ and  $b^\perp = N(A^T) b$. In that case, the norm can be developped in:
$$ || A x - b ||^2 = || A x - \tilde{b} - b^\perp ||^2 = || A x - \tilde{b} ||^2 + || b^\perp ||^2 $$
this $b=\tilde{b}+b^\perp$ and $\tilde{b}^T b^\perp=0$. The right term does not depends on $x$ and the minimization problem can be reformulated by the root problem:
$$ \underset{x\in\mathbb{R}^m}{\textrm{find}}   A x = b$$
with $b = \tilde b \in R(A)$. One solution to this problem is evidently given by the pseudoinverse. We then just have to show that the pseudoinverse is the unique minimum-norm solution $x^* = A^+ b$. Suppose that there exist another solution $x$ such that $Ax=b$. Then $A(x-x^*) = 0$, \mie $x-x^* \in N(A)$. Since $x^* \in N(A)^\perp$, we have:
$$ || x ||^2 = || x-x^*  ||^2 + || x^* ||^2 $$ 
which is minimum when $x=x^*$.
\end{proof}

The minimum-norm least-square can be seen has a problem in two levels:
\begin{enumerate}
\item Minimize the sum of square of the residual $||Ax-b||$.
\item Among the set of solution of the first objective, minimize the parameter norm.
\end{enumerate}

\subsection{Elements of calcul}

\subsubsection{From the decomposition}

The pseudoinverse gives the closed-form of the least square solution. Its expression can be reduced using the SVD:
$$ x^* = V_1 \Sigma^{-1} U_1^T b$$
The coefficients of the pseudoinverse should not be computed explicitely in practice to avoid unecessary extra computation cost. Indeed, the optimum is compute from the SVD by $x^* = V_1 \Big( \Sigma^{-1} \big( U_1^T b \big) \Big)$.

In this SVD-based writting, the only divisions are those necessary to invert the diagonal $(\sigma_1 .. \sigma_r)$. The computation cost is then mainly in the matrix multiplications ($O(n^2)$) and the decomposition itself. The SVD is computed by a complex 2-stage algorithm that converges toward the exact decomposition but only approximate it in a finite number of steps. Its complexity is in $O(n^3)$, with a large coefficient in place of the $O$ (typically 20). Rather than the SVD, some other decomposition can be used.

\subsubsection{Complete orthogonal decomposition}

A complete orthogonal decomposition (COD) is any decomposition such that:
$$ A = ULV^T = \BIN U_1 & U_0 \BOUT \BIN L_1 & 0 \\ 0 & 0 \BOUT \BIN V_1 & V_0 \BOUT^T $$
where $U = \BIN U_1 & U_0 \BOUT$ and $V = \BIN V_1 & V_0 \BOUT$ are orthonormal matrices and $L_1$ is invertible (this last property justifying the ``complete'' adjective). With this definition, the SVD is a COD. Most of the time, COD is used when $L$ is lower triangular.

If the matrix $A$ is full-column rank, then $V=I_n$ and the COD corresponds to the well QR decomposition. If the matrix $A$ is full-row rank, then $U=I_n$ and the COD corresponds to QR of $A^T$ (also called LQ of $A$).

The COD can be computed in two stages, the first one to compute $U$, the second to compute $V$ (or conversly). The first stage is then similar to a rank-reaveling QR decomposition.

\subsubsection{QR decomposition}

The reference book for the algorithmics of matrix decomposition is [Golub96]. The book is a must for implementing any matrix algorithm, in particular QR, COD, SVD or Cholesky. We present quickly here the Givens method to compute the QR. 

The idea of the Givens method is to ``dig'' the upper part of $A$ to introduce zeros, by composing a sequence of elementary eponym rotations.
A Givens rotation $R_{i,j,\alpha}$ on $\mathbb{R}^m$ is a planar rotation of angle $\alpha$ on the two axis $i$ and $j$ of the canonical basis:
$$ R_{i,j,\alpha} = \BIN 
1 & 0      & \dots &              & & & & &  \dots & 0 \\
0 & \ddots &       &              & & & & & & \vdots \\
\vdots  &        & 1     &              & & & & & & \\
  &        &       & \cos(\alpha) &0& \dots  &0&-\sin(\alpha) & & \\
  &        &       & 0            &1&        & &0 & & \\
  &        &       & \vdots       & &\ddots  & &\vdots & & \\
  &        &       & 0            & &        &1&0 & & \\
  &        &       & \sin(\alpha) &0&\dots   & &\cos(\alpha) & & \\
  &        &       &              & &        & & &1 \ \ \ \ & 0\\
\vdots  &        &       &              & &        & & & \ \ \ \ \ \ddots & \vdots \\
0  &  \dots      &       &              & &        & & \dots& 0 &1  \\
\BOUT
$$

Then, for $\alpha = tan^{-1}( \frac{[A]_{i,l}}{[A]_{j,l}}$, the rotation nullifies one elemement of the column $l$ of $A$:
$$ [R_{i,j,\alpha} A]_{i,l} = 0, \quad  [R_{i,j,\alpha} A]_{j,l} = \sqrt{[A]_{i,l}^2 + [A]_{j,l}^2}$$

The Givens rotations are applied successively to ``dig'' the last columns of $A$ until the diagonal elements, then the second to last column, etc until the second column, where only one element is nullified and that conclude the decomposition:
$$ 
\BIN 
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
\quad \rightarrow
\BIN 
\times &\times &\times &0  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
\quad \rightarrow
\BIN 
\times &\times &\times &0  \\
\times &\times &\times &0  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
$$
$$
\quad \rightarrow
\BIN 
\times &\times &\times &0  \\
\times &\times &\times &0  \\
\times &\times &\times &0  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
\quad \rightarrow
\BIN 
\times &\times &0 &0  \\
\times &\times &0  &0  \\
\times &\times &\times &0  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
\quad \rightarrow 
\BIN 
\times &0 &0 &0  \\
\times &\times &0 &0  \\
\times &\times &\times &0  \\
\times &\times &\times &\times  \\
\times &\times &\times &\times  \BOUT
$$

\subsubsection{After the QR}
After the left basis $U$ is computed as a sequence of Givens rotation, the same method can be expressed to obtain the right basis $V$. At the end of the two phases of the algorithm, the coefficients of $L_1$ are explicitely expressed, but not those of $U$ nor $V$. It is not necessary to explicitely compute them to obtain the least-square solution. The algorithm is the following:
\begin{enumerate}
\item $\beta := U^T b$ :  apply the sequence of left Givens to $b$
\item $\tilde{b} := \beta_{1:r}$: only keep the upper part of $\beta$, which correspond to the projection in the range of $A$.
\item $y := L_1 \setminus \tilde{b}$: compute the substitution of $L$ on $\tilde{b}$.
\item $x^* := V \BIN y \\ 0 \BOUT$: express the obtain solution in the canonical basis.
\end{enumerate}

Using the same Givens rotations, the matrix $A$ can be ``digged'' up to a bidiagonal form. From this first stage, the SVD can be approximated by iteratively nullifying the bigest non-diagonal elements. The second part of the algorithm typically converges in a $O(n)$ number of iteration to an approximation in the range of the machine precision. The bidiagonal requires more iterations to be obtained than simply the triangular $L_1$. Furthermore, the second stage increases again the cost of the SVD algorithm.

\subsubsection{Algorithmic cost}

The COD requires $O(n^3)$ real multiplications (with typically 9 in factor to the cube). It is the predominant cost. Then, the basis multiplications requires $O(n^2)$ iterations (typically factor $O=4$ of each). The triangle substitution requires $O(r^2)$ (with $O=2$). 

The cost importantly increases if the explicit expression of the bases $U$ or $V$ are required ($O(n^3)$ each) or if the pseudoinverse is explicitely needed. In that case, it corresponds to $n$ substitution and basis multiplication, for an added $O(n^3)$ (with typically $O=6$).

A detailed discussion of the algorithmic cost is proposed in [Golub96]. In general, the carefull engenieer would take care to which elements are really needed in his computations before asking its value.

\subsection{Regularization}

The Tikhonov regularized least-square problem is:
$$ \min_{x\in\mathcal{R}^m} ||A x - b ||^2 + \eta^2 ||x||^2 $$
where $\eta\in\mathbb{R}^+$ is the regularization or damping parameter. When $\eta$ is null, we obtain the classical least-square problem. On the opposite, the solution $x^*$ tends toward 0 when $\eta$ goes to infinity. The parameter adjust the relative precision of the solution to the classical least square problem with respect to a penalization of the large values of $x$.

The solution to this problem is obtained by writting the pseudoinverse of $A_\eta = \BIN A \\ \eta I_n \BOUT$, or, using the property $A_\eta^+ = (A_\eta^TA_\eta)^+A_\eta^T$, we have:
$$ x^* = (A^T A + \eta^2 I_n )^+ A^T b $$
The obtained matrix is called the regularized (or damped) inverse of $A$ and denoted by:
$$ A^{\dagger \eta} \triangleq (A^T A + \eta^2 I_n )^+ A^T $$

Using the SVD of $A$, it is easy to show that the regularized inverse is equal to:
$$ A^{\dagger \eta} = V_1 \Sigma^{\dagger \eta} U_1^T $$
where the coefficients $\sigma_i^{\dagger \eta}$ of $\Sigma^{\dagger \eta}$ are given by:
$$\sigma_i^{\dagger \eta} \triangleq \frac{\sigma_i}{\sigma_i^2 + \eta^2}$$

The $\sigma_i^{\dagger \eta}$ tends toward the $\sigma_i^+ \triangleq \frac{1}{\sigma_i}$ when $\eta$ tends toward 0, which proves that the regularized inverse tends toward the pseudoinverse when the regularization is arbitrarily small.

One interesting aspect of the regularized least-square problem is that its minimum is always unique.

The regularized problem is often prefered to the classical one when small singular values can be expected. In particular, this problem corresponds to the one iteratively solved in the Levenberg-Marquardt algorithm.


% ##############################################################################
\chapter{Resolution of the inverse-kinematics problem}

\section{Inverting the Jacobian}
\section{Task function}
\subsection{Formal definition}
\subsection{Examples}
Center of mass, relative placement, visual servoing

% ##############################################################################
\chapter{Redundancy}

\section{Projection}
\subsection{Projected gradient}
\subsection{Second task}
\subsection{Stack of tasks}
\subsection{Regularization}

\section{Weighted inverse}
\subsection{Definition}
\subsection{Resolution}


% ##############################################################################
\chapter{Active-set search}

% ##############################################################################
% ##############################################################################
% ##############################################################################
\part{Inverse dynamics}

\chapter{Overview by Andrea Del Prete}

\section{Motivations}

What is better in inverse dynamics:
\begin{itemize}
\item  dynamics is a better model: the robot is better modeled as a force source than as a velocity source.
\item Rigid contact: no control on the contact force by controling the velocity
\item Friendly robotics: the robot is never exerting a large force 
\end{itemize}

\section{Task function}

We consider a function of the robot configuration, namely $x$:
$$ x = f(q) $$
The function $f$ could also depends on the robot velocity or other state components. We keep $q$ for simplicity. We want to impose a certain behavior on the function output. 

\section{Forward model}
Inverse kinematics: the basic model is.
$$ \dot x = J(q) \dot q$$
The control is $\dot q$.

Inverse dynamics: we need to find a relation between the robot torques $\tau$ and the objectives. Typically, knowing $\tau$, what is $\ddot q$ then what is the task acceleration $\ddot x$.
$$\tau \rightarrow \ddot q \rightarrow \ddot x $$

\subsection{Robot dynamics overview}
The dynamic equation is 
$$ M(q) \ddot q + C(q,\dot q)\dot q + g(q) = \tau $$ where $M(q)$ is called the
mass matrix, $C(q,\dot q) \dot q$ are the Coriolis and centrifugal effects and
$g(q)$ is the gravity force. This states the relation between $\tau$ and $\ddot
q$, the terms in $q$ and $\dot q$ being the state of the robot.

The forward dynamics is: being given $q,\dot q$ and $\tau$, what is the resulting $\ddot q$. This typically what dynamics engines of simulators do:
$$ FWD: q,\dot q,\tau \rightarrow \ddot q$$
The inverse dynamics is: being given $q,\dot q,\ddot q$, what is the necessary $\tau$ to achieve this acceleration. This is typically what robot control does:
$$ INV: q,\dot q,\ddot q \rightarrow \tau$$

[Say a word about invertibility?]

\subsection{Deriviation}
Most naive way of deriving: coming from Newton law: $F = m \ddot x$, on each rigid body of the robot taken separately. The problem is that we will have also to find the constraint forces, i.e. the constraints that prevent the joint constraints from being violated.

Lagrange approach. First define the Lagragian:
$$L(q,\dot q) = T(q,\dot q) - U(q)$$
where $T(.,.)$ is the kinetic energy, and $U(.)$ is the potential energy. The Lagrangian respects:
\EIN{lagrangian}\frac{d}{dt} \dpartial{L(q,\dot q)}{\dot q} - \dpartial{L(q,\dot q)}{q} = \tau
\EOUT
If taking a free body (in SE(3)), this last equation boils down to standard Newton $F= m \ddot x$. This is to give the intuition behind the equation, without proof.

\subsubsection{Kinetic energy}
Let's now derive $T$ and $U$. The kinematic energy $T_i$ of one link $i$ is:
$$T_i(q,\dot q) = \frac{1}{2} m_i \dot x_i^2 + \frac{1}{2} w_i^T I_i w_i$$
where $m_i$ is the mass of the link, $I_i \in \mathbb{R}^{3\times 3}$ its inertia, $\dot x_i$ is linear velocity and $w_i$ its angular velocity. We can rewrite it spatially by:
$$T_i(q,\dot q) = \frac{1}{2} \nu_i^T M_i \nu_i$$
with $\nu_i$ is the kinematics twist, and $M_i$ is a $6 \times 6$ matrix deduced from $m_i$ and $I_i$. 

The total system energy is the sum of the $T_i$ over all the bodies:
$$ T(q,\dot q) = \sum_{i=1}^n \frac{1}{2} \nu_i^T M_i \nu_i $$
This comes down to the simple form:
$$ T(q,\dot q) = \frac{1}{2} \qdot^T M \qdot $$
where the generalized inertia matrix is: 
$$M =  \sum_{i=1}^n  J_i^T M_i J_i $$
using the fact that $\nu_i = J_i \qdot$. $M$ is positive definite, which is important in the following.

\subsubsection{Potential energy}
The potential energy of one body is:
$$U_i(q) = m_i g h_i(q)$$
The total potential energy of the system is then:
$$ U(q) = \sum_{i=1}^n  m_i g h_i(q)$$

\subsubsection{Energy derivation}
$$ \dpartial{T(q,\qdot)}{\qdot} = M(q) \qdot$$
$$ \frac{d}{dt} \dpartial{T(q,\qdot)}{\qdot} = M(q) \qddot + \dot{M}(q) \qdot$$

$$\dpartial{T}{q} = \frac{1/2} \qdot^T \dpartial{M}{q}(q) \qdot$$
where $dpartial{M}{q}$ is a tensor (3D matrix), no detail given yet about the tensor/vector product.

The Lagrangian derivatives \eq{eq:lagrangian} can finally be rewritten:
$$ M(q) \qddot + (\dot{M}(q) -  \frac{1}{2} \qdot^2 \dpartial{M}{q}) \qdot + \dpartial{U}{q} = \tau$$
We find the correspondance with: $C(q,\qdot) = \dot{M}(q) -  \frac{1}{2} \qdot^2 \dpartial{M}{q}$ and $g(q) = \dpartial{U}{q}$. In the following, we denote by $h(q,\qdot) = C(q,\qdot) \qdot+ g(q)$ the dynamic affine term.

\section{Inverse dynamics control}

\subsection{First control law: computed torque}

We denote by $\tau^*$ the control law (the $^*$ makes explicit the fact that this is an imposed quantity). The computed torque is simply:
$$\tau^* = M \qddot^* + h$$
The desired acceleration is set to:
$$\qddot^* = \qddot^d - K_p (q - q^d) - K_v (\dot q - \dot q^d)$$

The dynamics of the close-loop system is obtained by putting the $\tau^*$ form into the dynamics equation, which trivially leads to:
$$ \qddot = \qddot^d - K_p e - K_v \dot e$$
where $e = q-q^d$. We then have the differential second-order linear equation:
$$\ddot e + K_v \dot e + K_p e = 0$$
which brings the error to 0 as soon as $K_p$ and $K_v$ are positive.

\subsection{Quadratic program}

The computed torque is trivially obtained from the following QP:
$$  \tau^* = \min_{\tau \in \mathbb{R}^n} || \qddot - \qddot^* || $$
$$ \textrm{so that} \quad M \qddot + h = \tau $$

For a ``simple'' objectives such as tracking $\qddot^*||$, the QP is a trivial formulation, but much more flexible for more complex cases like we will see below.

\section{Mobile robot in contact}

\subsection{Case of the underactuation}

We consider the case of a free floating robot. The configuration of the robot will then comprehend 6 DOF that represent the position of the robot base. The robot configuration is then explicitly distinguished:
$$ q = \BIN x_b \\ q_a \BOUT $$
where $q_a$ are the actuated joints (they have motors, you can directly control them) and $x_b$ is a representation of the robot basis, typically using a representation of $SE(3)$. The robot dynamic equation is then:
$$ M \qddot + h = \BIN 0 \\ \tau \BOUT = S^T \tau$$
where $S = \BIN 0_6 \\ I_n \BOUT$ is the selection matrix (so that $S q = q_a$).

\subsection{Contact forces}
If the system is in contact with the environment, then the contact forces are acting on the system and should be considered in the Lagrangian. The contact forces are exerting an equivalent torque at the joint level, given by:
$$ \tau_{c} = J_c^T f_c$$
where $f_c$ are the Cartesian contact forces (i.e. the force exerted on the contact body, in whatever representation you line) and $J_c$ is the Jacobian of the contact points where the forces are exerted. Let us prove that. The principle of D'Alembert (virtual work) states that the power of the contact force (Cartesian contact force times the displacement) is equal to the total power (joint torque times the configuration displacement:
$$f^T \delta x = \tau^T \delta q$$
where $\delta x$ is the Cartesian displacement at the contact point and $\delta q$ is the configuration displacement. Since $\delta x= J \delta q$ we have for any $\delta q$:
$$\delta q^T \tau = \delta q^T J^T f$$
By identification, this prooves that $\tau = J^T f$.
%
The dynamic equation is then:
$$ M \qddot + h = S^T \tau + J_c^T f_c$$
The contact force $f_c$ enters as a new variable that should be found when searching for the motor torques. 

Example of forces: 
\begin{itemize}
\item point contact: f is dim 3
\item planar contact: you can exert 3 forces and three torques, f is dimension 6.
\item several contacts: just stack the forces for each bodies in contact.
\end{itemize}
[There is some work to do here about duality?]

\section{Operational space inverse dynamics (OSID)}

\subsection{Task-space acceleration}

The task kinematics is:
$$\dot x = J \qdot$$
Derivating this relation with respect to time:
$$ \ddot x = J \qddot + \dot J \qdot$$

Classical case: moving $x$ from a starting point $x^0$ to a reference target $x^\infty$. If assuming that a reference trajectory $x^d(t)$ is given from $x^0$ to $x^\infty$ (with its time derivatives $\dot x^d, \ddot x^d$). The imposed Cartesian acceleration should be:
$$ \ddot x^* = \ddot x^d - K_p(x-x^d) - K_v (\dot x - \dot x^d) $$
Like for the proportional-derivative on $q$, the $x$ acceleration is composed of two part: a feedforward $\ddot x^d$ and a feedback $K_p+K_v$. The feedforward is not sufficient in practice, as modeling and actuation errors prevent a perfect application of the feedforward. The feedback makes the control robust.

\subsection{OSID problem}

The problem of finding $\tau$ that meets at best the imposed task acceleration is then written:
$$ \min_{\tau \in \mathbb{R}^n} || J \qddot + \dot J \qdot - \ddot x^* ||^2$$
$$ \textrm{so that} M \qddot + h = S^T \tau$$
This is a constrained quadratic problem.

\subsection{Constrained quadratic problem}

Let us consider the generic linearly-constrained linear least-square problem (LCLLSP):
\EIN{LCLLSP} \min_{y \in \mathbb{R}^n} || A y - b ||^2 \EOUT
$$ \textrm{so that} C y = d$$
We assume that the constraint is feasible, that is to say $d$ is in the range of $C$ (which is typically the case in the simpler case when $C$ is full row rank). This is a reasonible assumption, as an unfeasible constraint means that the LCLLSP as no solution.

The space of all $y$ that satisfy the constraint can be described using the null space of $C$; it is the set of $\bar y$ of the form:
$$ \bar y = C^+ d + Z^T z$$
where $Z$ is a basis of the null space of $C$, that can be obtained from the SVD as $Z=V_0$ using:
$$ C = \BIN U_1 & U_0 \BOUT \BIN \Sigma & 0 \\ 0 & 0 \BOUT \BIN V_1 & V_0 \BOUT^T$$
It is straight forward to check that any $\bar y$ of this form respect the constraint ($C\bar y= CC^+ d + CZz = d + 0$ since $CC^+d=d$ by assumption of $d$ being in the range of $C$ and $CZ=0$  by definition of $Z$). The LCLLSP is then reduced to a unconstrained LLSP:
$$ \min_{z \in \mathbb{R}^{m-r}} || AZz - (b - AC^+ d) ||^2 $$
whose solution is directly obtained using the pseudoinverse of $AZ$, leading finally to the least-norm solution of \eq{eq:LCLLSP}:
$$ y^* = C^+d + Z(AZ)^+ ( b - AC^+d)$$

[Proof of norm minimality of $y^*$ ?]

[Explanation of the cascade... introducing the null space of $AZ$]

\subsection{OSID with contact}

The previous section directly gives the optimum of the OSID problem. Let us now consider the resolution of the OSID in case of contact. We now have three variables: $\tau, \qddot$ and $f_c$. In addition to the dynamics constraint, we also have the constraint that the robot movements should correspond to the contact model. Typically, a rigid contact model imposes no motion of the contact point (therefore decoupling the force from the motion). This is written $x_c(q) = x_c^0$ where $x_c^0$ is a constant position. The constraint is written in terms of $\qddot$ by derivating it twice with respect to time:
$$ J_c \qddot + \dot J_c \qdot = 0$$
The OSID with contact finally can be written as the following LCLLSP:
\EIN{OSIDf} \min_{\tau \in \mathbb{R}^n} || J \qddot + \dot J \qdot - \ddot x^* ||^2 \EOUT
$$ \textrm{so that} M \qddot + h = S^T \tau + J_c^T f_c$$
$$ \quad J_c \qddot + \dot J_c \qdot = 0$$
This is written under the form \eq{eq:LCLLSP} by setting:
$$ y = (\qddot, f, \tau)$$
$$ A = \BIN J & 0 & 0 \BOUT$$
$$ b = \ddot x^* - \dot J \qdot$$
$$ C = \BIN  M & -J_c^T & -S^T \\ J_c & 0 & 0 \BOUT$$
$$ d = (-h, -\dot J_c qdot)$$

Using variations of $A$, it is also possible to express objectives in terms of contact forces (for ex, applying a given reference force when cleaning the board).

\subsection{Elements of computations}

The typical control frequency when imposing torques is 1kHz, which means that the control should be solved in 1ms. The typical dimension of the OSID problem with contact is: 2n+k+6 variables (n the number of joints, k the number of contact); n+6+k constraints. For a standard humanoid, n=30, k=20 (i.e. 86 variables, 50 constraints), which is too high for a brut force resolution of \eq{eq:OSIDf} in real time.

A computational reduction is achieved by exploiting the sparsity of the problem. This can be done at no implementation cost by using our knowledge of the specific form of the problem, coming from the dynamics. We split all the quantities in the configuration space between the non-actuated floating base (indexed by $u$) and the actuated DOF (indexed by $a$):
$$ M = \BIN M_u \\ M_a \BOUT, $$


\chapter{Geometry of forces and accelerations}

\chapter{The dynamic equation of a multi-body system}

\section{Recursive Newton-Euler algorithm}

\chapter{Operational-space inverse dynamics}

\chapter{Synthesis: an overview of constrained optimization}

% ##############################################################################
% ##############################################################################
% ##############################################################################
\part{Optimal control}

%% \chapter{Inifinite-space optimization}
%% \chapter{Discretization and static optimization}
%% \chapter{Linear-quadratic resolution}

In the three first parts, we have only considered instantaneous approximation of the problem. In Part 1, we have only considered the static problem of finding one configuration satisfying a set of constraints. In the second part, we have shown that the pseudo-path obtained by integrating the search for the optimal configuration can be viewed as a trajectory joining an initial configuration to its optimum. However, we did not really select this trajectory and it is very unlikely that the resulting one is optimizing any interesting criteria. In Part 3, we have considered the robot dynamics, which is closely related to the notion of trajectory. However, once more, we only looked at the instantaneous linearization of the dynamics and obtained a trajectory by integration of the instantaneous control. 

In this part, we now consider directly the trajectory of the system and work on its properties to obtain an optimal movement form the start point to the end point. The trajectory is a function of time in the space of both control and states. It is then evolving in a space of infinite dimension. Finding a minimum over a functional, that is to say a function of functions, can be viewed as a generalization of the problem of minimization over a finite-dimension vector space. It is called calculus of variation. In our case, the state and control trajectories are linked by the dynamics, which is formulated as a ordinary differential equation of control. The corresponding problem is called optimal control, that is to say the minimization over a functional of the state and control trajectories constrained by the control differential equation. In the ``good'' cases, it can be viewed as a special case of the calculus of variation. In many cases (even not so difficult), the optimal-control class of problem goes beyond calculus of variation.

In a first time, we make a brief overview of the optimal-control formulation and theoretical results. On a numerical point of view, the actual optimal-control problems are very often too difficult to be solved using this results. In these cases, we then approximate the problem by considering a finite-dimension basis of function for the state and the control (for example time discretization) and rely on finite-dimension optimization to find the best approximation to the initial problem. This so-called ``direct'' approach is the subject of the second chapter of this part.


% ##############################################################################
\chapter{Problem formulation and properties}

In this part, we give an overview of the theoretical results of the optimal-control field. The content of this chapter would very well be the topic of a 25-hour class and 250-pages book. The idea here is to provide a brief introduction and an insight of what would be the alternatives to a direct resolution. We first formulate the problem, then gives to related formulation to provide an insight of the difficulty of the optimal-control class. The main results are formulated without proofs in the third section. They enable the formulation of the indirect resolution methods, that we briefly describe and discuss.

% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Definition of the problem}

\subsection{Robot dynamics}

Up to now, we only describe the robot by its current configuration. If we consider for example the control to be the joint torques, as in the previous part, the robot configuration is certainly not enough to describe the current state of the robot and the action of the torque control on it: the joint velocities are missing and should be considered in the state. In that case, the joint acceleration are not part of the state since infinitely many acceleration are instantaneously possible when chosing the torque control. More precisely, at a given time $t$ and for a known configuration and velocity, it is not possible to know the acceleration until the torque controls are chosen. 

More generally, the state is chosen with respect to the control in order to uniquely define the effect of the first on the second. The dynamics is then given as a very abstract ordinary differential equation linking the state. Denoting by $x(t)$ the state and by $u(t)$ the control at time $t$, the dynamics equation is written:
$$ \dot x(t) = f(x(t),u(t)) $$
We only consider here for simplicity autonomous dynamics, \mie that are not explicitely function of time. The same results are obtained with time-varying dynamics, where the time partial derivative of $f$ acts as a drift to be compensated. This case is not so frequent in robotics.

The choice of $x$ and $u$, and the consequent dynamics $f$ are the modeling choice of the programmer. One can for example consider the simple dynamics:
$$ x = q, \quad \dot x = \dot q, \quad f: x,u \rightarrow u$$
This dynamics in fact only consider the kinematics of the system, and not what we called dynamics in the previous part (the robot inertia, forces and acceleration).

The dynamics of the previous part is:
$$ x = (q,\dot q), \quad u = \tau, \quad f: x,u \rightarrow \BIN \dot q \\ M(q)^{-1} (b(q,\dot q) - \tau) \BOUT$$
with $M$ the robot generalized inertia matrix, $b$ the dynamics drift vector and $\tau$ the joint torques.

In this last equation, we do not consider the actuator dynamics, since the control is directly at the joint output level. The motor dynamics can be added. For example, a direct-current electrical motor would be control for example in current, which does not significantly complexify the dynamics model. Depending on the level of modeling, the motor temperature might be added to the state and affect the motor behavior. An air cylinder would be controled by the electrical current opening the servo-valve that makes the air flow enter in the tube, changing the pressure and producing torque. In that case, the state as to be increased to render the air flow state, which increases the degree of the differential equation. 

\subsection{Cost functionnal}

The cost is defined as a general functionnal over both the control and the state time-dependant functions. In order to make explicit that a functionnal manipulates a function of the time, and not one instance at a fixed time, we emphasize the notation of $x$ and $u$, defining the functional by:
$$ g: \traj{x},\traj{u} \rightarrow g(\traj{x},\traj{u})$$
The emphase is ommited when the function nature of $x$ and $u$ are evident, for example in denoting $x(t)$.
Very often, it is reduced to the following form:
$$ g(\traj{x},\traj{u}) = c(x(t_f)|t_f) + \int_0^{t_f} c(x(t),u(t)|t) dt $$
where $t_f \in \overline{\mathbb{R}}^+$ is the terminal time, $c(.|t_f)$ is the terminal cost and $c(.,.|t)$ is the running (or integral) cost. The terminal cost can be free (\mie a variable of the problem) or fixed, infinite (in such a case, $c(.|t_f)$ is null) or bounded. In the following, we will only consider  fixed finite terminal time, for simplicity. The same properties can be adapted for the other cases.

This form of the cost functionnal is named the Lagrange-Mayer form. Two other forms are very often considered. The Lagrange form only consider the integral term:
$$ g(\traj{x},\traj{u}) = \int_0^{t_f} c(x(t),u(t)|t) dt $$
The Mayer form only consider the terminal term:
$$ g(\traj{x},\traj{u}) = c(x(t_f)|t_f)$$
Theoretically, these three forms are strictly equivalent, as any problem in one of them can be reformulated under the other forms. For example, it is possible to pass from the the Lagrange-Mayer to the Mayer by considering an additional variable $x^0$ subject to the dynamics $\dot x^0(t) = c(x(t),u(t)$ and setting the complete dynamics to be $\tilde{\traj x} = (\traj x,\traj{x}^0)$ and $\tilde f = (f,c)$. The Mayer cost is then $\tilde g(\tilde{\traj x},\tilde{\traj u}) = c(x(T)) + x^0(T)$. This equivalence also emphasize the symmetry between the running cost and the dynamics functions.

\subsection{Optimal control formulation}

In the following, we will consider the optimal control problem of the Lagrange-Mayer form:
\EIN{oc_cost} \min_{\traj x,\traj u} c(x(t_f)) + \int_0^{t_f} c(x(s),u(s)) ds
\EOUT
\EIN{oc_dyn} s.t. \quad \dot x(t) = f(x(t),u(t) \EOUT

% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Trajectory optimization: Boundary-value problem}

\subsection{Problem formulation}
\subsection{Shooting resolution}
\subsection{Numerical integration methods}
\subsection{Multiple-shooting resolution}

% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Infinite-dimension optimization: calculus of variation }

% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Optimality conditions}

The optimal-control problem can be seen as an unconstrained minimization only over the $\traj u$ trajectory, as $\traj x$ is then uniquely defined by the integration of the dynamics. We denotes this functional by:
$$ J(\traj u|x_0) = c(x(t_f) + \int_0^{t_f} c(x(s),u(s)) ds $$
We abusively use the same notation to denote the partial cost:
$$ J(\traj u|x_t,t) = c(x(t_f) + \int_t^{t_f} c(x(s),u(s)) ds $$
The functionnal depends on the initial point $x_t$ and of the starting time $t$. Here $x_t$ is a fixed state (finite dimension) while $\traj u: [t,t_f] \rightarrow \mathcal{U}$ is a time-dependent function. 


\subsection{Bellman principle}

The Bellman optimality principle simply states that, for any trajectory $\traj u$ minizing $J(\traj u|x,0)$, a subtrajectory of $\traj u$ starting at $t$ minimizes $J(.|x(t),t)$. To write this principle explicitely, we define the optimum of $J$ to be the value function $V$:
$$V^*(x,t) = \min_{u_{[t,t_f]}} J(u|x,t)$$
We then have of course:
$$ V^*(x,t_f) = c(x)$$

The Bellman principle is written as a recursive definition of $V^*$:
$$V^*(x,t) = \min_{u_{[t,t+\Delta t]}} \left\{ \int_t^{t+\Delta t} c(x(s),u(s)) ds + V^*(x(t+\Delta t),t+\Delta t) \right\}$$

The value function is a complete solution of the optimal-control problem that directly gives the optimal trajectories starting from any point of the space. It is not possible to express it in general, neither to compute it numerically.



\subsection{Equation of Hamilton-Jacobi-Bellman}

The Bellman optimality principle can be perceived as an optimal dynamics for the system. In particular, assuming that it is possible to obtain the first order Taylor development of $V^*$:
$$V^*(x(t+\Delta t),t+\Delta t) = V^*(x(t),t) + V_t^*(x(t),t) \Delta t + V_x^*(x(t),t) f(x(t),u(t)) \Delta t + o(\Delta t^2)$$
where we denote with indexes the partial derivatives:
$$ V_t^* \triangleq \dpartial{V^*}{t} $$
$$ V_x^* \triangleq \dpartial{V^*}{x} $$

The development can be propagated through the Bellman equation. For a small $\Delta t$, the integral becomes trivial. We then have
\begin{align*}
 V^*(x(t),t) = \min{ u_{[t,t+\Delta t]}} \Big\{ & c(x(t),u(t)) \Delta t + V^*(x(t),t) + 
V_t^*(x(t),t) \Delta t \\ &+ V_x^*(x(t),t) f(x(t),u(t)) \Delta t \Big\}
\end{align*}
Finally, we can take out of the $\min$ operator the terms not depending of $u$ and obtained the following partial derivative equation:
$$ V_t(x(t),t) = \max_{u(t) \in \mathcal{U}} \Big\{ - c(x(t),u(t))  - V_x^*(x(t),t) f(x(t),u(t)) \Big\} $$

We define the system Hamiltonian $H$ to be:
$$H(x(t),u(t),p) = <p | f(x(t),u(t))> - c(x(t),u(t)$$
for any vector $p \in \mathcal{X}$\footnote{We will see late $p$ as the costate, living in the dual of the state space. This notation in $p \in \mathcal{X}$ is then strictly-speaking abusive.}. The differential equation is then reformulated with the Hamiltonian as:
$$ V_t(x(t),t) = \max_{u(t) \in \mathcal{U}} \Big\{ H(x(t),u(t),-V_x(x(t))) \Big\} $$

The choice of have a max on $-V_x$ or a min on $V_x$ is arbitrary. We chose this convention to follow Pontryagin point of view of the trajectory optimality as a maximum.

This differential equation is called Hamilton-Jacobi-Bellman equation. It provides a very powerful result, that is a necessary but also a sufficient condition of optimality (we only here roughly derivated the necessary side). In general the HJB equation is very difficult to solve or integrate. When it is possible, it results in the value function, which gives all the solutions of the system.

The optimal control corresponds to the argmax of the HJB equation:
$$ u^*(t) = \textrm{arg}\max_{u(t) \in \mathcal{U}} \Big\{ H(x(t),u(t),-V_x(x(t))) \Big\} $$

\subsection{Pontryagin Maximum Principle}

The HJB equation is somehow too powerful. First, it does not hold for some classes of systems. In particular, we have used the calculus-of-variation point of view to obtain it, using a limited development of the value function that does not necessarily exists. For more general classes of system, the condition of optimality is given by the Pontryagin maximum principle.

\begin{theorem}[Weak Maximum principle]
Let $\traj u^* : [0,t_f] \rightarrow \mathcal U$ be the global optimum of \eq{eq:oc_cost} subject to the dynamics \eq{eq:oc_dyn}, and $\traj x^* : [0,t_f] \rightarrow \mathcal X$ the corresponding trajectory. Then there exists a costate trajectory $\traj p^* : [0,t_f] \rightarrow \mathcal X$ such that:
$$ \dot x^* = H_p (x^*,u^*,p^*) $$ 
$$ \dot p^* = - H_x (x^*,u^*,p^*) $$ 
Then, for any $t \in [0,t_f]$, the control maximize the Hamiltonian:
$$ u^*(t) = \max_{u \in \mathcal{U} } H(x^*(t),u,p^*(t))$$
\end{theorem}

This is a weak formulation of the PMP, as it does not consider any constraints on the control nor state trajectories, nor any terminal conditions. The weak PMP is not too difficult to demonstate. The complete PMP is much more difficult. The interested reader is referred to Pontryagin book or to [Liberzon03].

\subsection{Discussion}
HJB states that the control can be computed as:
$$ u^*(t) = \textrm{arg}\max_{u(t) \in \mathcal{U}} \Big\{ H(x^*(t),u(t),-V_x(x(t))) \Big\} $$
On the other hand, PMP states a similar equation including $p^*$:
$$ u^*(t) = \textrm{arg}\max_{u(t) \in \mathcal{U}} \Big\{ H(x^*(t),u(t),p^*(t))) \Big\} $$

The two principles are then very similar. However, assuming that we are able to compute the value function $V^*$, the HJB provides also a feedback formulation, that is to say 


% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Indirect methods}


% ##############################################################################
\chapter{Direct resolution}

% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Discretization and non-linear finite-dimension optimization}
% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Explicit versus implict formulation}
% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Direct multiple shooting}
% #-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-#-
\section{Linear-quadratic optimization}
\subsection{Gauss-Newton hypothesis}

% ##############################################################################
\chapter{The example of the robot walk}


\end{document}
